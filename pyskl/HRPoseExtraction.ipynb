{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Main\\envs\\HRNet\\lib\\site-packages\\mmcv\\__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python38\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "try:\n",
    "    import mmdet\n",
    "    from mmdet.apis import inference_detector, init_detector\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    raise ImportError('Failed to import `inference_detector` and '\n",
    "                      '`init_detector` form `mmdet.apis`. These apis are '\n",
    "                      'required in this script! ')\n",
    "\n",
    "try:\n",
    "    import mmpose\n",
    "    from mmpose.apis import inference_top_down_pose_model, init_pose_model\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    raise ImportError('Failed to import `inference_top_down_pose_model` and '\n",
    "                      '`init_pose_model` form `mmpose.apis`. These apis are '\n",
    "                      'required in this script! ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import torch\n",
    "from mmcv.ops import RoIPool\n",
    "from mmcv.parallel import collate, scatter\n",
    "from mmcv.runner import load_checkpoint\n",
    "\n",
    "from mmdet.core import get_classes\n",
    "from mmdet.datasets import replace_ImageToTensor\n",
    "from mmdet.datasets.pipelines import Compose\n",
    "from mmdet.models import build_detector\n",
    "\n",
    "def inference_detectorV2(model, imgs):\n",
    "    \"\"\"Inference image(s) with the detector.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The loaded detector.\n",
    "        imgs (str/ndarray or list[str/ndarray] or tuple[str/ndarray]):\n",
    "           Either image files or loaded images.\n",
    "\n",
    "    Returns:\n",
    "        If imgs is a list or tuple, the same length list type results\n",
    "        will be returned, otherwise return the detection results directly.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(imgs, (list, tuple)):\n",
    "        is_batch = True\n",
    "    else:\n",
    "        imgs = [imgs]\n",
    "        is_batch = False\n",
    "\n",
    "    cfg = model.cfg\n",
    "    device = next(model.parameters()).device  # model device\n",
    "\n",
    "    if isinstance(imgs[0], np.ndarray):\n",
    "        cfg = cfg.copy()\n",
    "        # set loading pipeline type\n",
    "        cfg.data.test.pipeline[0].type = 'LoadImageFromWebcam'\n",
    "\n",
    "    cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
    "    test_pipeline = Compose(cfg.data.test.pipeline)\n",
    "\n",
    "    datas = []\n",
    "    for img in imgs:\n",
    "        # prepare data\n",
    "        if isinstance(img, np.ndarray):\n",
    "            # directly add img\n",
    "            data = dict(img=img)\n",
    "        else:\n",
    "            # add information into dict\n",
    "            data = dict(img_info=dict(filename=img), img_prefix=None)\n",
    "        # build the data pipeline\n",
    "        data = test_pipeline(data)\n",
    "        datas.append(data)\n",
    "\n",
    "    data = collate(datas, samples_per_gpu=len(imgs))\n",
    "    # just get the actual data from DataContainer\n",
    "    data['img_metas'] = [img_metas.data[0] for img_metas in data['img_metas']]\n",
    "    data['img'] = [img.data[0] for img in data['img']]\n",
    "    if next(model.parameters()).is_cuda:\n",
    "        # scatter to specified GPU\n",
    "        data = scatter(data, [device])[0]\n",
    "    else:\n",
    "        for m in model.modules():\n",
    "            assert not isinstance(\n",
    "                m, RoIPool\n",
    "            ), 'CPU inference with RoIPool is not supported currently.'\n",
    "\n",
    "    # forward the model\n",
    "    with torch.no_grad():\n",
    "        results = model(return_loss=False, rescale=True, **data)\n",
    "\n",
    "    if not is_batch:\n",
    "        return results[0]\n",
    "    else:\n",
    "        return results\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import decord\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch.distributed as dist\n",
    "from mmcv.runner import get_dist_info, init_dist\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyskl.smp import mrlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "det_score_thr = 0.7\n",
    "det_area_thr = 1600\n",
    "default_mmdet_root = \"D:/FYP/HAR-ZSL-XAI/pyskl/mmdetection\"\n",
    "default_mmpose_root = \"D:/FYP/HAR-ZSL-XAI/pyskl/mmpose\"\n",
    "default_det_config = (\n",
    "    f'{default_mmdet_root}/configs/faster_rcnn/'\n",
    "    'faster_rcnn_r50_caffe_fpn_mstrain_1x_coco-person.py')\n",
    "default_det_ckpt = (\n",
    "    'https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/'\n",
    "    'faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth')\n",
    "default_pose_config = (\n",
    "    f'{default_mmpose_root}/configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/'\n",
    "    'coco/hrnet_w32_coco_256x192.py')\n",
    "default_pose_ckpt = (\n",
    "    'https://download.openmmlab.com/mmpose/top_down/hrnet/'\n",
    "    'hrnet_w32_coco_256x192-c78dce93_20200708.pth')\n",
    "\n",
    "def extract_frame(video_path):\n",
    "    vid = decord.VideoReader(video_path)\n",
    "    return [x.asnumpy() for x in vid]\n",
    "\n",
    "\n",
    "def detection_inference(model, frames):\n",
    "    results = []\n",
    "    for frame in frames:\n",
    "        result = inference_detector(model, frame)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "def pose_inference(model, frames, det_results):\n",
    "    assert len(frames) == len(det_results)\n",
    "    total_frames = len(frames)\n",
    "    num_person = max([len(x) for x in det_results])\n",
    "    kp = np.zeros((num_person, total_frames, 17, 3), dtype=np.float32)\n",
    "\n",
    "    for i, (f, d) in enumerate(zip(frames, det_results)):\n",
    "        # Align input format\n",
    "        d = [dict(bbox=x) for x in list(d)]\n",
    "        pose = inference_top_down_pose_model(model, f, d, format='xyxy')[0]\n",
    "        for j, item in enumerate(pose):\n",
    "            kp[j, i] = item['keypoints']\n",
    "    return kp\n",
    "\n",
    "def gen_video_list(file_path:str):\n",
    "    annotations = []\n",
    "    for __path in glob.glob(os.path.join(file_path,\"*\",\"*.mp4\")):\n",
    "        p_parts = __path.split(os.path.sep)\n",
    "        cls_name = p_parts[-2]\n",
    "\n",
    "        annotations.append(dict(\n",
    "            frame_dir=osp.basename(__path).split('.')[0],\n",
    "            file_path=__path,\n",
    "            filename=p_parts[-1],\n",
    "            label=cls_name\n",
    "        ))\n",
    "\n",
    "    return annotations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "video_paths = \"../data/nipun_video_dataset/PAMAP2_K10_V1\"\n",
    "save_paths = \"HRNetSkeletons\"\n",
    "video_set_name = \"nipun_video_dataset/PAMAP2_K10_V1\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco-person/faster_rcnn_r50_fpn_1x_coco-person_20201216_175929-d022e227.pth\n"
     ]
    }
   ],
   "source": [
    "det_model = init_detector(default_det_config, default_det_ckpt, 'cuda')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from http path: https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w32_coco_256x192-c78dce93_20200708.pth\n"
     ]
    }
   ],
   "source": [
    "pose_model = init_pose_model(default_pose_config, default_pose_ckpt, 'cuda')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "vid_list = gen_video_list(video_paths)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/180 [00:00<?, ?it/s]d:\\fyp\\har-zsl-xai\\pyskl\\mmdetection\\mmdet\\datasets\\utils.py:66: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  warnings.warn(\n",
      "  4%|▍         | 8/180 [05:12<1:51:58, 39.06s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m     res \u001B[38;5;241m=\u001B[39m res[box_areas \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m det_area_thr]\n\u001B[0;32m     15\u001B[0m     det_results[i] \u001B[38;5;241m=\u001B[39m res\n\u001B[1;32m---> 17\u001B[0m pose_results \u001B[38;5;241m=\u001B[39m \u001B[43mpose_inference\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpose_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdet_results\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m shape \u001B[38;5;241m=\u001B[39m frames[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m2\u001B[39m]\n\u001B[0;32m     19\u001B[0m anno[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimg_shape\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m anno[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moriginal_shape\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m shape\n",
      "Cell \u001B[1;32mIn[4], line 40\u001B[0m, in \u001B[0;36mpose_inference\u001B[1;34m(model, frames, det_results)\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (f, d) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(frames, det_results)):\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;66;03m# Align input format\u001B[39;00m\n\u001B[0;32m     39\u001B[0m     d \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mdict\u001B[39m(bbox\u001B[38;5;241m=\u001B[39mx) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(d)]\n\u001B[1;32m---> 40\u001B[0m     pose \u001B[38;5;241m=\u001B[39m \u001B[43minference_top_down_pose_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mxyxy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j, item \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(pose):\n\u001B[0;32m     42\u001B[0m         kp[j, i] \u001B[38;5;241m=\u001B[39m item[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkeypoints\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32mD:\\Anaconda\\Main\\envs\\HRNet\\lib\\site-packages\\mmcv\\utils\\misc.py:340\u001B[0m, in \u001B[0;36mdeprecated_api_warning.<locals>.api_warning_wrapper.<locals>.new_func\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    337\u001B[0m             kwargs[dst_arg_name] \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(src_arg_name)\n\u001B[0;32m    339\u001B[0m \u001B[38;5;66;03m# apply converted arguments to the decorated method\u001B[39;00m\n\u001B[1;32m--> 340\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mold_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    341\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "File \u001B[1;32mD:\\Anaconda\\Main\\envs\\HRNet\\lib\\site-packages\\mmpose\\apis\\inference.py:392\u001B[0m, in \u001B[0;36minference_top_down_pose_model\u001B[1;34m(model, imgs_or_paths, person_results, bbox_thr, format, dataset, dataset_info, return_heatmap, outputs)\u001B[0m\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [], []\n\u001B[0;32m    390\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OutputHook(model, outputs\u001B[38;5;241m=\u001B[39moutputs, as_tensor\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m h:\n\u001B[0;32m    391\u001B[0m     \u001B[38;5;66;03m# poses is results['pred'] # N x 17x 3\u001B[39;00m\n\u001B[1;32m--> 392\u001B[0m     poses, heatmap \u001B[38;5;241m=\u001B[39m \u001B[43m_inference_single_pose_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    393\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    394\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimgs_or_paths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    395\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbboxes_xywh\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    396\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    397\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdataset_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    398\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_heatmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_heatmap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    399\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_multi_frames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multi_frames\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    401\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m return_heatmap:\n\u001B[0;32m    402\u001B[0m         h\u001B[38;5;241m.\u001B[39mlayer_outputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mheatmap\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m heatmap\n",
      "File \u001B[1;32mD:\\Anaconda\\Main\\envs\\HRNet\\lib\\site-packages\\mmpose\\apis\\inference.py:267\u001B[0m, in \u001B[0;36m_inference_single_pose_model\u001B[1;34m(model, imgs_or_paths, bboxes, dataset, dataset_info, return_heatmap, use_multi_frames)\u001B[0m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# forward the model\u001B[39;00m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 267\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimg\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimg_metas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimg_metas\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_heatmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_heatmap\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpreds\u001B[39m\u001B[38;5;124m'\u001B[39m], result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutput_heatmap\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Anaconda\\Main\\envs\\HRNet\\lib\\site-packages\\mmcv\\runner\\fp16_utils.py:119\u001B[0m, in \u001B[0;36mauto_fp16.<locals>.auto_fp16_wrapper.<locals>.new_func\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    116\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m@auto_fp16 can only be used to decorate the \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    117\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmethod of those classes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msupported_types\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mhasattr\u001B[39m(args[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfp16_enabled\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m args[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mfp16_enabled):\n\u001B[1;32m--> 119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mold_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;66;03m# get the arg spec of the decorated method\u001B[39;00m\n\u001B[0;32m    122\u001B[0m args_info \u001B[38;5;241m=\u001B[39m getfullargspec(old_func)\n",
      "File \u001B[1;32mD:\\Anaconda\\Main\\envs\\HRNet\\lib\\site-packages\\mmpose\\models\\detectors\\top_down.py:142\u001B[0m, in \u001B[0;36mTopDown.forward\u001B[1;34m(self, img, target, target_weight, img_metas, return_loss, return_heatmap, **kwargs)\u001B[0m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_loss:\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_train(img, target, target_weight, img_metas,\n\u001B[0;32m    141\u001B[0m                               \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_test\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m    \u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimg_metas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_heatmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_heatmap\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\Main\\envs\\HRNet\\lib\\site-packages\\mmpose\\models\\detectors\\top_down.py:174\u001B[0m, in \u001B[0;36mTopDown.forward_test\u001B[1;34m(self, img, img_metas, return_heatmap, **kwargs)\u001B[0m\n\u001B[0;32m    170\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbbox_id\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m img_metas[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    172\u001B[0m result \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m--> 174\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackbone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwith_neck:\n\u001B[0;32m    176\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneck(features)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Anaconda\\Main\\envs\\HRNet\\lib\\site-packages\\mmpose\\models\\backbones\\hrnet.py:593\u001B[0m, in \u001B[0;36mHRNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    591\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    592\u001B[0m         x_list\u001B[38;5;241m.\u001B[39mappend(y_list[i])\n\u001B[1;32m--> 593\u001B[0m y_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstage4\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_list\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    595\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y_list\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Anaconda\\Main\\envs\\HRNet\\lib\\site-packages\\mmpose\\models\\backbones\\hrnet.py:200\u001B[0m, in \u001B[0;36mHRModule.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbranches[\u001B[38;5;241m0\u001B[39m](x[\u001B[38;5;241m0\u001B[39m])]\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_branches):\n\u001B[1;32m--> 200\u001B[0m     x[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbranches\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    202\u001B[0m x_fuse \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    203\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuse_layers)):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Anaconda\\Main\\envs\\HRNet\\lib\\site-packages\\mmpose\\models\\backbones\\resnet.py:124\u001B[0m, in \u001B[0;36mBasicBlock.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    122\u001B[0m     out \u001B[38;5;241m=\u001B[39m cp\u001B[38;5;241m.\u001B[39mcheckpoint(_inner_forward, x)\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 124\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43m_inner_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    126\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32mD:\\Anaconda\\Main\\envs\\HRNet\\lib\\site-packages\\mmpose\\models\\backbones\\resnet.py:109\u001B[0m, in \u001B[0;36mBasicBlock.forward.<locals>._inner_forward\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    107\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(x)\n\u001B[0;32m    108\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm1(out)\n\u001B[1;32m--> 109\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    111\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(out)\n\u001B[0;32m    112\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(out)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\activation.py:102\u001B[0m, in \u001B[0;36mReLU.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\functional.py:1455\u001B[0m, in \u001B[0;36mrelu\u001B[1;34m(input, inplace)\u001B[0m\n\u001B[0;32m   1453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(relu, (\u001B[38;5;28minput\u001B[39m,), \u001B[38;5;28minput\u001B[39m, inplace\u001B[38;5;241m=\u001B[39minplace)\n\u001B[0;32m   1454\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[1;32m-> 1455\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelu_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1457\u001B[0m     result \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28minput\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for anno in tqdm(vid_list):\n",
    "        frames = extract_frame(anno['file_path'])\n",
    "        det_results = detection_inference(det_model, frames)\n",
    "        # * Get detection results for human\n",
    "        det_results = [x[0] for x in det_results]\n",
    "        for i, res in enumerate(det_results):\n",
    "            # * filter boxes with small scores\n",
    "            res = res[res[:, 4] >= det_score_thr]\n",
    "            # * filter boxes with small areas\n",
    "            box_areas = (res[:, 3] - res[:, 1]) * (res[:, 2] - res[:, 0])\n",
    "            assert np.all(box_areas >= 0)\n",
    "            res = res[box_areas >= det_area_thr]\n",
    "            det_results[i] = res\n",
    "\n",
    "        pose_results = pose_inference(pose_model, frames, det_results)\n",
    "        shape = frames[0].shape[:2]\n",
    "        anno['img_shape'] = anno['original_shape'] = shape\n",
    "        anno['total_frames'] = len(frames)\n",
    "        anno['num_person_raw'] = pose_results.shape[0]\n",
    "        anno['keypoint'] = pose_results[..., :2].astype(np.float16)\n",
    "        anno['keypoint_score'] = pose_results[..., 2].astype(np.float16)\n",
    "        #anno.pop('filename')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(save_paths,video_set_name,anno[\"label\"]),exist_ok=True)\n",
    "with open(os.path.join(save_paths,video_set_name,f'combined.pkl'),\"wb\") as f0:\n",
    "    pickle.dump(anno,f0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
