{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nipun\\anaconda3\\envs\\fyp_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.models.modeling_sgn import embed, local, gcn_spa, compute_g_spa\n",
    "from src.models.modeling_lxmert import LxmertConfig, LxmertXLayer\n",
    "\n",
    "import torch \n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x216eb71a8e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGNEncoder(nn.Module):\n",
    "    def __init__(self, num_joint, seg, hidden_size=128, bs=32, is_3d=True, train=True, bias=True, device='cpu'):\n",
    "        super(SGNEncoder, self).__init__()\n",
    "\n",
    "        self.dim1 = hidden_size\n",
    "        self.dim_unit = hidden_size // 4 \n",
    "        self.seg = seg\n",
    "        self.num_joint = num_joint\n",
    "        self.bs = bs\n",
    "\n",
    "        if is_3d:\n",
    "          self.spatial_dim = 3\n",
    "        else:\n",
    "          self.spatial_dim = 2\n",
    "\n",
    "        if train:\n",
    "            self.spa = self.one_hot(bs, num_joint, self.seg)\n",
    "            self.spa = self.spa.permute(0, 3, 2, 1).to(device)\n",
    "            self.tem = self.one_hot(bs, self.seg, num_joint)\n",
    "            self.tem = self.tem.permute(0, 3, 1, 2).to(device)\n",
    "        else:\n",
    "            self.spa = self.one_hot(32 * 5, num_joint, self.seg)\n",
    "            self.spa = self.spa.permute(0, 3, 2, 1).to(device)\n",
    "            self.tem = self.one_hot(32 * 5, self.seg, num_joint)\n",
    "            self.tem = self.tem.permute(0, 3, 1, 2).to(device)\n",
    "\n",
    "        self.tem_embed = embed(self.seg, joint=self.num_joint, hidden_dim=self.dim_unit*4, norm=False, bias=bias)\n",
    "        self.spa_embed = embed(num_joint, joint=self.num_joint, hidden_dim=self.dim_unit, norm=False, bias=bias)\n",
    "        self.joint_embed = embed(self.spatial_dim, joint=self.num_joint, hidden_dim=self.dim_unit, norm=True, bias=bias)\n",
    "        self.dif_embed = embed(self.spatial_dim, joint=self.num_joint, hidden_dim=self.dim_unit, norm=True, bias=bias)\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d([1, 1])\n",
    "        self.cnn = local(self.dim1, self.dim1 * 2, bias=bias)\n",
    "        self.compute_g1 = compute_g_spa(self.dim1 // 2, self.dim1, bias=bias)\n",
    "        self.gcn1 = gcn_spa(self.dim1 // 2, self.dim1 // 2, bias=bias)\n",
    "        self.gcn2 = gcn_spa(self.dim1 // 2, self.dim1, bias=bias)\n",
    "        self.gcn3 = gcn_spa(self.dim1, self.dim1, bias=bias)\n",
    "\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "\n",
    "        nn.init.constant_(self.gcn1.w.cnn.weight, 0)\n",
    "        nn.init.constant_(self.gcn2.w.cnn.weight, 0)\n",
    "        nn.init.constant_(self.gcn3.w.cnn.weight, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Dynamic Representation\n",
    "        x = x.view((self.bs, self.seg, self.num_joint, self.spatial_dim))\n",
    "        x = x.permute(0, 3, 2, 1).contiguous()\n",
    "        dif = x[:, :, :, 1:] - x[:, :, :, 0:-1]\n",
    "        dif = torch.cat([dif.new(self.bs, dif.size(1), self.num_joint, 1).zero_(), dif], dim=-1)\n",
    "        # print(x.shape)\n",
    "        pos = self.joint_embed(x)\n",
    "        tem1 = self.tem_embed(self.tem)\n",
    "        spa1 = self.spa_embed(self.spa)\n",
    "        dif = self.dif_embed(dif)\n",
    "        dy = torch.add(pos, dif)\n",
    "        # Joint-level Module\n",
    "        x= torch.cat([dy, spa1], 1)\n",
    "        g = self.compute_g1(x)\n",
    "        x = self.gcn1(x, g)\n",
    "        x = self.gcn2(x, g)\n",
    "        x = self.gcn3(x, g)\n",
    "        # Frame-level Module\n",
    "        # x = torch.add(x, tem1)\n",
    "        x = self.cnn(torch.add(x, tem1))\n",
    "        output_feat = torch.squeeze(x).permute(0,2,1)\n",
    "\n",
    "        return output_feat\n",
    "    def one_hot(self, bs, spa, tem):\n",
    "        y = torch.arange(spa).unsqueeze(-1)\n",
    "        y_onehot = torch.FloatTensor(spa, spa)\n",
    "\n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1, y, 1)\n",
    "\n",
    "        y_onehot = y_onehot.unsqueeze(0).unsqueeze(0)\n",
    "        y_onehot = y_onehot.repeat(bs, tem, 1, 1)\n",
    "\n",
    "        return y_onehot\n",
    "\n",
    "    \n",
    "class BiLSTMDecoder(nn.Module):\n",
    "    def __init__(self,seq_len, input_size, hidden_size, linear_filters,embedding_size:int, num_layers = 1,bidirectional=True, device='cpu'):\n",
    "        super(BiLSTMDecoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.num_layers = num_layers\n",
    "        self.linear_filters = linear_filters[::-1]\n",
    "        self.embedding_size = embedding_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "\n",
    "        # define LSTM layer\n",
    "        self.layers = []\n",
    "        # add lstm\n",
    "        self.lstm = nn.LSTM(input_size = self.seq_len, hidden_size = self.hidden_size,\n",
    "                            num_layers = self.num_layers, bidirectional=True,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.maxpool = nn.AdaptiveMaxPool2d([self.seq_len, self.seq_len])\n",
    "        # add linear layers \n",
    "        if bidirectional:\n",
    "            self.layers.append(nn.Linear(2*hidden_size,self.linear_filters[0]))\n",
    "        else:\n",
    "            self.layers.append(nn.Linear(hidden_size,self.linear_filters[0]))\n",
    "\n",
    "        for __id,layer_in in enumerate(self.linear_filters):\n",
    "            if __id == len(linear_filters)-1:\n",
    "                self.layers.append(nn.Linear(layer_in,self.input_size))\n",
    "            else:\n",
    "                self.layers.append(nn.Linear(layer_in,self.linear_filters[__id+1]))\n",
    "\n",
    "        self.net = nn.Sequential(*self.layers)\n",
    "\n",
    "\n",
    "    def forward(self,encoder_hidden):\n",
    "        \"\"\"\n",
    "        : param x_input:               input of shape (seq_len, # in batch, input_size)\n",
    "        : return lstm_out, hidden:     lstm_out gives all the hidden states in the sequence; hidden gives the hidden state and cell state for the last element in the sequence\n",
    "        \"\"\"\n",
    "        output = self.maxpool(encoder_hidden)\n",
    "        lstm_out, self.hidden = self.lstm(output)\n",
    "        x = self.net(lstm_out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BiLSTMDecoder(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size, num_layers = 1, bidirectional=True, batch_size=32, device='cpu'):\n",
    "#         super(BiLSTMDecoder, self).__init__()\n",
    "#         self.input_size = input_size\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.bidirectional = bidirectional\n",
    "#         self.batch_size = batch_size\n",
    "#         self.device = device\n",
    "\n",
    "#         # add lstm layer\n",
    "#         self.lstm = nn.LSTM(input_size = input_size, hidden_size = self.hidden_size,\n",
    "#                             num_layers = self.num_layers, bidirectional=self.bidirectional,\n",
    "#                             batch_first=True, proj_size = output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         '''\n",
    "#         : param x_input:               input of shape (seq_len, # in batch, input_size)\n",
    "#         : return lstm_out, hidden:     lstm_out gives all the hidden states in the sequence; hidden gives the hidden state and cell state for the last element in the sequence                         \n",
    "#         '''\n",
    "        \n",
    "#         # x = self.net(x_input)\n",
    "#         out, _ = self.lstm(x)\n",
    " \n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMUTransformerEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        config: (dict) configuration of the model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.transformer_dim = config.get(\"transformer_dim\")\n",
    "\n",
    "        self.input_proj = nn.Sequential(nn.Conv1d(config.get(\"input_dim\"), self.transformer_dim, 1), nn.GELU(),\n",
    "                                        nn.Conv1d(self.transformer_dim, self.transformer_dim, 1), nn.GELU(),\n",
    "                                        nn.Conv1d(self.transformer_dim, self.transformer_dim, 1), nn.GELU(),\n",
    "                                        nn.Conv1d(self.transformer_dim, self.transformer_dim, 1), nn.GELU())\n",
    "\n",
    "        self.window_size = config.get(\"window_size\")\n",
    "        self.encode_position = config.get(\"encode_position\")\n",
    "        encoder_layer = TransformerEncoderLayer(d_model = self.transformer_dim,\n",
    "                                       nhead = config.get(\"nhead\"),\n",
    "                                       dim_feedforward = config.get(\"dim_feedforward\"),\n",
    "                                       dropout = config.get(\"transformer_dropout\"),\n",
    "                                       activation = config.get(\"transformer_activation\"))\n",
    "\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer,\n",
    "                                              num_layers = config.get(\"num_encoder_layers\"),\n",
    "                                              norm = nn.LayerNorm(self.transformer_dim))\n",
    "        self.cls_token = nn.Parameter(torch.zeros((1, self.transformer_dim)), requires_grad=True)\n",
    "\n",
    "        if self.encode_position:\n",
    "            self.position_embed = nn.Parameter(torch.randn(self.window_size + 1, 1, self.transformer_dim))\n",
    "\n",
    "        # num_classes =  config.get(\"num_classes\")\n",
    "        # output_size = config.get(\"output_size\")\n",
    "        # self.imu_head = nn.Sequential(\n",
    "        #     nn.AvgPool2d((self.window_size,1)),\n",
    "        #     nn.Linear(self.transformer_dim,  output_size),\n",
    "        #     nn.GELU(),\n",
    "        #     nn.Dropout(0.1),\n",
    "        #     nn.Linear(output_size, output_size)\n",
    "        # )\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # init\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, data):\n",
    "        src = data  # Shape N x S x C with S = sequence length, N = batch size, C = channels\n",
    "        src = self.input_proj(src.transpose(1, 2)).permute(2, 0, 1)\n",
    "\n",
    "        cls_token = self.cls_token.unsqueeze(1).repeat(1, src.shape[1], 1)\n",
    "        src = torch.cat([cls_token, src])\n",
    "\n",
    "        if self.encode_position:\n",
    "            src += self.position_embed\n",
    "\n",
    "        target = self.transformer_encoder(src)\n",
    "        target = torch.squeeze(target.permute(1,0,2))\n",
    "        # target = torch.squeeze(self.imu_head(target))\n",
    "        return target\n",
    "\n",
    "def get_activation(activation):\n",
    "    \"\"\"Return an activation function given a string\"\"\"\n",
    "    if activation == \"relu\":\n",
    "        return nn.ReLU(inplace=True)\n",
    "    if activation == \"gelu\":\n",
    "        return nn.GELU()\n",
    "    raise RuntimeError(\"Activation {} not supported\".format(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierHead(nn.Module):\n",
    "  def __init__(self, window_size, embedding_size, hidden_size):\n",
    "        super(ClassifierHead, self).__init__()\n",
    "        #   self.maxpool = nn.AdaptiveMaxPool2d([embedding_size//2, 2])\n",
    "      #   self.hidden = nn.Linear(embedding_size, embedding_size)\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.output = nn.Linear(embedding_size, 1)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "        self.imu_head = nn.Sequential(\n",
    "            nn.AvgPool2d((window_size,1)),\n",
    "            nn.Linear(embedding_size,  hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "  def forward(self, x):\n",
    "        output = self.imu_head(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(BaseModel, self).__init__()\n",
    "        \n",
    "        self.imu_model = IMUTransformerEncoder(config['imu_config'])\n",
    "        self.skel_encoder = SGNEncoder(**config['sgn_config'])\n",
    "        self.skel_decoder = BiLSTMDecoder(**config['dec_config'])\n",
    "        self.fc_head = ClassifierHead(**config['clf_config'])\n",
    "        self.lxmert_config = LxmertConfig(**config['xmert_config'])\n",
    "        self.lxmert_xlayer = LxmertXLayer(self.lxmert_config)\n",
    "\n",
    "        self.num_layers = config['num_layers']\n",
    "\n",
    "    def forward(self, x_imu, x_skel):\n",
    "        imu_feats = self.imu_model(x_imu)\n",
    "        skel_feats = self.skel_encoder(x_skel)\n",
    "        print(f\"imu_feats {imu_feats.shape} | skel_feats {skel_feats.shape}\")\n",
    "        for i in range(self.num_layers):\n",
    "            x_outputs = self.lxmert_xlayer(\n",
    "                lang_feats = skel_feats,\n",
    "                lang_attention_mask = None,  \n",
    "                visual_feats = imu_feats,\n",
    "                visual_attention_mask = None,\n",
    "                input_id = None,\n",
    "                output_attentions=False,\n",
    "            )\n",
    "            skel_feats, imu_feats = x_outputs[:2]\n",
    "\n",
    "        print(f\"imu_feats {imu_feats.shape} | skel_feats {skel_feats.shape}\")\n",
    "        skel_recon = self.skel_decoder(skel_feats)\n",
    "        # imu_feats = torch.squeeze(imu_feats)\n",
    "        bin_output = self.fc_head(imu_feats)\n",
    "        return bin_output, skel_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_config = {\n",
    "\t\"input_dim\": 54,\n",
    "    \"window_size\":24,\n",
    "\t\"encode_position\":True,\n",
    "\t\"transformer_dim\": 512,\n",
    "\t\"nhead\": 8,\n",
    "\t\"num_encoder_layers\": 6, \n",
    "\t\"dim_feedforward\": 128, \n",
    "\t\"transformer_dropout\": 0.1, \n",
    "\t\"transformer_activation\": \"gelu\",\n",
    "\t\"head_activation\": \"gelu\",\n",
    "    \"baseline_dropout\": 0.1,\n",
    "\t\"batch_size\": 32,\n",
    "\t\"output_size\": 512\n",
    "}\n",
    "\n",
    "sgn_config = {\n",
    "    'num_joint': 12,\n",
    "    'seg': 60,\n",
    "    'hidden_size': 256,\n",
    "    'train': True,\n",
    "    'bs': 32,\n",
    "    'is_3d': False\n",
    "}\n",
    "\n",
    "# dec_config = {\n",
    "#     'input_size': 512,\n",
    "#     'hidden_size': 256,\n",
    "#     'output_size': 12,\n",
    "#     'num_layers': 2,\n",
    "#     'bidirectional': True,\n",
    "#     # \"embedding_size\": 128,\n",
    "#     # \"linear_filters\":[128,256,512,1024],\n",
    "# }\n",
    "\n",
    "dec_config = {\n",
    "    'seq_len': 60,\n",
    "    'input_size': 24,\n",
    "    'hidden_size': 256,\n",
    "    'num_layers': 2,\n",
    "    'bidirectional': True,\n",
    "    \"embedding_size\": 512,\n",
    "    \"linear_filters\":[128,256,512,1024],\n",
    "}\n",
    "\n",
    "clf_config = {\n",
    "    'window_size': 25,\n",
    "    'embedding_size': 512,\n",
    "    'hidden_size': 256\n",
    "}\n",
    "\n",
    "\n",
    "base_config = {\n",
    "    'imu_config': imu_config,\n",
    "    'sgn_config': sgn_config,\n",
    "    'dec_config': dec_config,\n",
    "    'clf_config': clf_config,\n",
    "    'num_layers': 1,\n",
    "    'xmert_config': {\n",
    "        'vocab_size': 1024,\n",
    "        'hidden_size': 512,\n",
    "        'num_attention_heads': 2,\n",
    "        'intermediate_size': 512\n",
    "    }\n",
    "}\n",
    " \n",
    "base_model = BaseModel(base_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_input = torch.randn((32, 24, 54))\n",
    "skel_input = torch.randn((32, 60, 24))\n",
    "y = torch.randint(low=0, high=2, size=(32,)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imu_feats torch.Size([32, 25, 512]) | skel_feats torch.Size([32, 60, 512])\n",
      "imu_feats torch.Size([32, 25, 512]) | skel_feats torch.Size([32, 60, 512])\n"
     ]
    }
   ],
   "source": [
    "imu_output, skel_output = base_model(imu_input, skel_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 60, 24])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skel_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imu_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clossfunc = nn.BCELoss()\n",
    "rlossfunc = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "closs = clossfunc(torch.squeeze(imu_output), y)\n",
    "rloss = rlossfunc(skel_input, skel_output)\n",
    "loss = closs + rloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imu_model.cls_token tensor(True)\n",
      "imu_model.position_embed tensor(True)\n",
      "imu_model.input_proj.0.weight tensor(True)\n",
      "imu_model.input_proj.0.bias tensor(True)\n",
      "imu_model.input_proj.2.weight tensor(True)\n",
      "imu_model.input_proj.2.bias tensor(True)\n",
      "imu_model.input_proj.4.weight tensor(True)\n",
      "imu_model.input_proj.4.bias tensor(True)\n",
      "imu_model.input_proj.6.weight tensor(True)\n",
      "imu_model.input_proj.6.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.0.self_attn.in_proj_weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.0.self_attn.in_proj_bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.0.self_attn.out_proj.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.0.self_attn.out_proj.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.0.linear1.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.0.linear1.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.0.linear2.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.0.linear2.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.0.norm1.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.0.norm1.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.0.norm2.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.0.norm2.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.1.self_attn.in_proj_weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.1.self_attn.in_proj_bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.1.self_attn.out_proj.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.1.self_attn.out_proj.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.1.linear1.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.1.linear1.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.1.linear2.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.1.linear2.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.1.norm1.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.1.norm1.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.1.norm2.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.1.norm2.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.2.self_attn.in_proj_weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.2.self_attn.in_proj_bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.2.self_attn.out_proj.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.2.self_attn.out_proj.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.2.linear1.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.2.linear1.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.2.linear2.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.2.linear2.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.2.norm1.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.2.norm1.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.2.norm2.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.2.norm2.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.3.self_attn.in_proj_weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.3.self_attn.in_proj_bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.3.self_attn.out_proj.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.3.self_attn.out_proj.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.3.linear1.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.3.linear1.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.3.linear2.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.3.linear2.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.3.norm1.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.3.norm1.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.3.norm2.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.3.norm2.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.4.self_attn.in_proj_weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.4.self_attn.in_proj_bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.4.self_attn.out_proj.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.4.self_attn.out_proj.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.4.linear1.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.4.linear1.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.4.linear2.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.4.linear2.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.4.norm1.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.4.norm1.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.4.norm2.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.4.norm2.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.5.self_attn.in_proj_weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.5.self_attn.in_proj_bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.5.self_attn.out_proj.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.5.self_attn.out_proj.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.5.linear1.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.5.linear1.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.5.linear2.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.5.linear2.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.5.norm1.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.5.norm1.bias tensor(True)\n",
      "imu_model.transformer_encoder.layers.5.norm2.weight tensor(True)\n",
      "imu_model.transformer_encoder.layers.5.norm2.bias tensor(True)\n",
      "imu_model.transformer_encoder.norm.weight tensor(True)\n",
      "imu_model.transformer_encoder.norm.bias tensor(True)\n",
      "skel_encoder.tem_embed.cnn.0.cnn.weight tensor(True)\n",
      "skel_encoder.tem_embed.cnn.0.cnn.bias tensor(True)\n",
      "skel_encoder.tem_embed.cnn.2.cnn.weight tensor(True)\n",
      "skel_encoder.tem_embed.cnn.2.cnn.bias tensor(True)\n",
      "skel_encoder.spa_embed.cnn.0.cnn.weight tensor(True)\n",
      "skel_encoder.spa_embed.cnn.0.cnn.bias tensor(True)\n",
      "skel_encoder.spa_embed.cnn.2.cnn.weight tensor(True)\n",
      "skel_encoder.spa_embed.cnn.2.cnn.bias tensor(True)\n",
      "skel_encoder.joint_embed.cnn.0.bn.weight tensor(True)\n",
      "skel_encoder.joint_embed.cnn.0.bn.bias tensor(True)\n",
      "skel_encoder.joint_embed.cnn.1.cnn.weight tensor(True)\n",
      "skel_encoder.joint_embed.cnn.1.cnn.bias tensor(True)\n",
      "skel_encoder.joint_embed.cnn.3.cnn.weight tensor(True)\n",
      "skel_encoder.joint_embed.cnn.3.cnn.bias tensor(True)\n",
      "skel_encoder.dif_embed.cnn.0.bn.weight tensor(True)\n",
      "skel_encoder.dif_embed.cnn.0.bn.bias tensor(True)\n",
      "skel_encoder.dif_embed.cnn.1.cnn.weight tensor(True)\n",
      "skel_encoder.dif_embed.cnn.1.cnn.bias tensor(True)\n",
      "skel_encoder.dif_embed.cnn.3.cnn.weight tensor(True)\n",
      "skel_encoder.dif_embed.cnn.3.cnn.bias tensor(True)\n",
      "skel_encoder.cnn.cnn1.weight tensor(True)\n",
      "skel_encoder.cnn.cnn1.bias tensor(True)\n",
      "skel_encoder.cnn.bn1.weight tensor(True)\n",
      "skel_encoder.cnn.bn1.bias tensor(True)\n",
      "skel_encoder.cnn.cnn2.weight tensor(True)\n",
      "skel_encoder.cnn.cnn2.bias tensor(True)\n",
      "skel_encoder.cnn.bn2.weight tensor(True)\n",
      "skel_encoder.cnn.bn2.bias tensor(True)\n",
      "skel_encoder.compute_g1.g1.cnn.weight tensor(True)\n",
      "skel_encoder.compute_g1.g1.cnn.bias tensor(True)\n",
      "skel_encoder.compute_g1.g2.cnn.weight tensor(True)\n",
      "skel_encoder.compute_g1.g2.cnn.bias tensor(True)\n",
      "skel_encoder.gcn1.bn.weight tensor(True)\n",
      "skel_encoder.gcn1.bn.bias tensor(True)\n",
      "skel_encoder.gcn1.w.cnn.weight tensor(True)\n",
      "skel_encoder.gcn1.w1.cnn.weight tensor(True)\n",
      "skel_encoder.gcn1.w1.cnn.bias tensor(True)\n",
      "skel_encoder.gcn2.bn.weight tensor(True)\n",
      "skel_encoder.gcn2.bn.bias tensor(True)\n",
      "skel_encoder.gcn2.w.cnn.weight tensor(True)\n",
      "skel_encoder.gcn2.w1.cnn.weight tensor(True)\n",
      "skel_encoder.gcn2.w1.cnn.bias tensor(True)\n",
      "skel_encoder.gcn3.bn.weight tensor(True)\n",
      "skel_encoder.gcn3.bn.bias tensor(True)\n",
      "skel_encoder.gcn3.w.cnn.weight tensor(True)\n",
      "skel_encoder.gcn3.w1.cnn.weight tensor(True)\n",
      "skel_encoder.gcn3.w1.cnn.bias tensor(True)\n",
      "skel_decoder.lstm.weight_ih_l0 tensor(True)\n",
      "skel_decoder.lstm.weight_hh_l0 tensor(True)\n",
      "skel_decoder.lstm.bias_ih_l0 tensor(True)\n",
      "skel_decoder.lstm.bias_hh_l0 tensor(True)\n",
      "skel_decoder.lstm.weight_ih_l0_reverse tensor(True)\n",
      "skel_decoder.lstm.weight_hh_l0_reverse tensor(True)\n",
      "skel_decoder.lstm.bias_ih_l0_reverse tensor(True)\n",
      "skel_decoder.lstm.bias_hh_l0_reverse tensor(True)\n",
      "skel_decoder.lstm.weight_ih_l1 tensor(True)\n",
      "skel_decoder.lstm.weight_hh_l1 tensor(True)\n",
      "skel_decoder.lstm.bias_ih_l1 tensor(True)\n",
      "skel_decoder.lstm.bias_hh_l1 tensor(True)\n",
      "skel_decoder.lstm.weight_ih_l1_reverse tensor(True)\n",
      "skel_decoder.lstm.weight_hh_l1_reverse tensor(True)\n",
      "skel_decoder.lstm.bias_ih_l1_reverse tensor(True)\n",
      "skel_decoder.lstm.bias_hh_l1_reverse tensor(True)\n",
      "skel_decoder.net.0.weight tensor(True)\n",
      "skel_decoder.net.0.bias tensor(True)\n",
      "skel_decoder.net.1.weight tensor(True)\n",
      "skel_decoder.net.1.bias tensor(True)\n",
      "skel_decoder.net.2.weight tensor(True)\n",
      "skel_decoder.net.2.bias tensor(True)\n",
      "skel_decoder.net.3.weight tensor(True)\n",
      "skel_decoder.net.3.bias tensor(True)\n",
      "skel_decoder.net.4.weight tensor(True)\n",
      "skel_decoder.net.4.bias tensor(True)\n",
      "fc_head.imu_head.1.weight tensor(True)\n",
      "fc_head.imu_head.1.bias tensor(True)\n",
      "fc_head.imu_head.4.weight tensor(True)\n",
      "fc_head.imu_head.4.bias tensor(True)\n",
      "lxmert_xlayer.visual_attention.att.query.weight tensor(True)\n",
      "lxmert_xlayer.visual_attention.att.query.bias tensor(True)\n",
      "lxmert_xlayer.visual_attention.att.key.weight tensor(True)\n",
      "lxmert_xlayer.visual_attention.att.key.bias tensor(True)\n",
      "lxmert_xlayer.visual_attention.att.value.weight tensor(True)\n",
      "lxmert_xlayer.visual_attention.att.value.bias tensor(True)\n",
      "lxmert_xlayer.visual_attention.output.dense.weight tensor(True)\n",
      "lxmert_xlayer.visual_attention.output.dense.bias tensor(True)\n",
      "lxmert_xlayer.visual_attention.output.LayerNorm.weight tensor(True)\n",
      "lxmert_xlayer.visual_attention.output.LayerNorm.bias tensor(True)\n",
      "lxmert_xlayer.lang_self_att.self.query.weight tensor(True)\n",
      "lxmert_xlayer.lang_self_att.self.query.bias tensor(True)\n",
      "lxmert_xlayer.lang_self_att.self.key.weight tensor(True)\n",
      "lxmert_xlayer.lang_self_att.self.key.bias tensor(True)\n",
      "lxmert_xlayer.lang_self_att.self.value.weight tensor(True)\n",
      "lxmert_xlayer.lang_self_att.self.value.bias tensor(True)\n",
      "lxmert_xlayer.lang_self_att.output.dense.weight tensor(True)\n",
      "lxmert_xlayer.lang_self_att.output.dense.bias tensor(True)\n",
      "lxmert_xlayer.lang_self_att.output.LayerNorm.weight tensor(True)\n",
      "lxmert_xlayer.lang_self_att.output.LayerNorm.bias tensor(True)\n",
      "lxmert_xlayer.visn_self_att.self.query.weight tensor(True)\n",
      "lxmert_xlayer.visn_self_att.self.query.bias tensor(True)\n",
      "lxmert_xlayer.visn_self_att.self.key.weight tensor(True)\n",
      "lxmert_xlayer.visn_self_att.self.key.bias tensor(True)\n",
      "lxmert_xlayer.visn_self_att.self.value.weight tensor(True)\n",
      "lxmert_xlayer.visn_self_att.self.value.bias tensor(True)\n",
      "lxmert_xlayer.visn_self_att.output.dense.weight tensor(True)\n",
      "lxmert_xlayer.visn_self_att.output.dense.bias tensor(True)\n",
      "lxmert_xlayer.visn_self_att.output.LayerNorm.weight tensor(True)\n",
      "lxmert_xlayer.visn_self_att.output.LayerNorm.bias tensor(True)\n",
      "lxmert_xlayer.lang_inter.dense.weight tensor(True)\n",
      "lxmert_xlayer.lang_inter.dense.bias tensor(True)\n",
      "lxmert_xlayer.lang_output.dense.weight tensor(True)\n",
      "lxmert_xlayer.lang_output.dense.bias tensor(True)\n",
      "lxmert_xlayer.lang_output.LayerNorm.weight tensor(True)\n",
      "lxmert_xlayer.lang_output.LayerNorm.bias tensor(True)\n",
      "lxmert_xlayer.visn_inter.dense.weight tensor(True)\n",
      "lxmert_xlayer.visn_inter.dense.bias tensor(True)\n",
      "lxmert_xlayer.visn_output.dense.weight tensor(True)\n",
      "lxmert_xlayer.visn_output.dense.bias tensor(True)\n",
      "lxmert_xlayer.visn_output.LayerNorm.weight tensor(True)\n",
      "lxmert_xlayer.visn_output.LayerNorm.bias tensor(True)\n"
     ]
    }
   ],
   "source": [
    "for name, param in base_model.named_parameters():\n",
    "    print(name, torch.isfinite(param.grad).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imu_model.cls_token\n",
      "imu_model.position_embed\n",
      "imu_model.input_proj.0.weight\n",
      "imu_model.input_proj.0.bias\n",
      "imu_model.input_proj.2.weight\n",
      "imu_model.input_proj.2.bias\n",
      "imu_model.input_proj.4.weight\n",
      "imu_model.input_proj.4.bias\n",
      "imu_model.input_proj.6.weight\n",
      "imu_model.input_proj.6.bias\n",
      "imu_model.transformer_encoder.layers.0.self_attn.in_proj_weight\n",
      "imu_model.transformer_encoder.layers.0.self_attn.in_proj_bias\n",
      "imu_model.transformer_encoder.layers.0.self_attn.out_proj.weight\n",
      "imu_model.transformer_encoder.layers.0.self_attn.out_proj.bias\n",
      "imu_model.transformer_encoder.layers.0.linear1.weight\n",
      "imu_model.transformer_encoder.layers.0.linear1.bias\n",
      "imu_model.transformer_encoder.layers.0.linear2.weight\n",
      "imu_model.transformer_encoder.layers.0.linear2.bias\n",
      "imu_model.transformer_encoder.layers.0.norm1.weight\n",
      "imu_model.transformer_encoder.layers.0.norm1.bias\n",
      "imu_model.transformer_encoder.layers.0.norm2.weight\n",
      "imu_model.transformer_encoder.layers.0.norm2.bias\n",
      "imu_model.transformer_encoder.layers.1.self_attn.in_proj_weight\n",
      "imu_model.transformer_encoder.layers.1.self_attn.in_proj_bias\n",
      "imu_model.transformer_encoder.layers.1.self_attn.out_proj.weight\n",
      "imu_model.transformer_encoder.layers.1.self_attn.out_proj.bias\n",
      "imu_model.transformer_encoder.layers.1.linear1.weight\n",
      "imu_model.transformer_encoder.layers.1.linear1.bias\n",
      "imu_model.transformer_encoder.layers.1.linear2.weight\n",
      "imu_model.transformer_encoder.layers.1.linear2.bias\n",
      "imu_model.transformer_encoder.layers.1.norm1.weight\n",
      "imu_model.transformer_encoder.layers.1.norm1.bias\n",
      "imu_model.transformer_encoder.layers.1.norm2.weight\n",
      "imu_model.transformer_encoder.layers.1.norm2.bias\n",
      "imu_model.transformer_encoder.layers.2.self_attn.in_proj_weight\n",
      "imu_model.transformer_encoder.layers.2.self_attn.in_proj_bias\n",
      "imu_model.transformer_encoder.layers.2.self_attn.out_proj.weight\n",
      "imu_model.transformer_encoder.layers.2.self_attn.out_proj.bias\n",
      "imu_model.transformer_encoder.layers.2.linear1.weight\n",
      "imu_model.transformer_encoder.layers.2.linear1.bias\n",
      "imu_model.transformer_encoder.layers.2.linear2.weight\n",
      "imu_model.transformer_encoder.layers.2.linear2.bias\n",
      "imu_model.transformer_encoder.layers.2.norm1.weight\n",
      "imu_model.transformer_encoder.layers.2.norm1.bias\n",
      "imu_model.transformer_encoder.layers.2.norm2.weight\n",
      "imu_model.transformer_encoder.layers.2.norm2.bias\n",
      "imu_model.transformer_encoder.layers.3.self_attn.in_proj_weight\n",
      "imu_model.transformer_encoder.layers.3.self_attn.in_proj_bias\n",
      "imu_model.transformer_encoder.layers.3.self_attn.out_proj.weight\n",
      "imu_model.transformer_encoder.layers.3.self_attn.out_proj.bias\n",
      "imu_model.transformer_encoder.layers.3.linear1.weight\n",
      "imu_model.transformer_encoder.layers.3.linear1.bias\n",
      "imu_model.transformer_encoder.layers.3.linear2.weight\n",
      "imu_model.transformer_encoder.layers.3.linear2.bias\n",
      "imu_model.transformer_encoder.layers.3.norm1.weight\n",
      "imu_model.transformer_encoder.layers.3.norm1.bias\n",
      "imu_model.transformer_encoder.layers.3.norm2.weight\n",
      "imu_model.transformer_encoder.layers.3.norm2.bias\n",
      "imu_model.transformer_encoder.layers.4.self_attn.in_proj_weight\n",
      "imu_model.transformer_encoder.layers.4.self_attn.in_proj_bias\n",
      "imu_model.transformer_encoder.layers.4.self_attn.out_proj.weight\n",
      "imu_model.transformer_encoder.layers.4.self_attn.out_proj.bias\n",
      "imu_model.transformer_encoder.layers.4.linear1.weight\n",
      "imu_model.transformer_encoder.layers.4.linear1.bias\n",
      "imu_model.transformer_encoder.layers.4.linear2.weight\n",
      "imu_model.transformer_encoder.layers.4.linear2.bias\n",
      "imu_model.transformer_encoder.layers.4.norm1.weight\n",
      "imu_model.transformer_encoder.layers.4.norm1.bias\n",
      "imu_model.transformer_encoder.layers.4.norm2.weight\n",
      "imu_model.transformer_encoder.layers.4.norm2.bias\n",
      "imu_model.transformer_encoder.layers.5.self_attn.in_proj_weight\n",
      "imu_model.transformer_encoder.layers.5.self_attn.in_proj_bias\n",
      "imu_model.transformer_encoder.layers.5.self_attn.out_proj.weight\n",
      "imu_model.transformer_encoder.layers.5.self_attn.out_proj.bias\n",
      "imu_model.transformer_encoder.layers.5.linear1.weight\n",
      "imu_model.transformer_encoder.layers.5.linear1.bias\n",
      "imu_model.transformer_encoder.layers.5.linear2.weight\n",
      "imu_model.transformer_encoder.layers.5.linear2.bias\n",
      "imu_model.transformer_encoder.layers.5.norm1.weight\n",
      "imu_model.transformer_encoder.layers.5.norm1.bias\n",
      "imu_model.transformer_encoder.layers.5.norm2.weight\n",
      "imu_model.transformer_encoder.layers.5.norm2.bias\n",
      "imu_model.transformer_encoder.norm.weight\n",
      "imu_model.transformer_encoder.norm.bias\n",
      "imu_model.imu_head.1.weight\n",
      "imu_model.imu_head.1.bias\n",
      "imu_model.imu_head.4.weight\n",
      "imu_model.imu_head.4.bias\n",
      "skel_encoder.tem_embed.cnn.0.cnn.weight\n",
      "skel_encoder.tem_embed.cnn.0.cnn.bias\n",
      "skel_encoder.tem_embed.cnn.2.cnn.weight\n",
      "skel_encoder.tem_embed.cnn.2.cnn.bias\n",
      "skel_encoder.spa_embed.cnn.0.cnn.weight\n",
      "skel_encoder.spa_embed.cnn.0.cnn.bias\n",
      "skel_encoder.spa_embed.cnn.2.cnn.weight\n",
      "skel_encoder.spa_embed.cnn.2.cnn.bias\n",
      "skel_encoder.joint_embed.cnn.0.bn.weight\n",
      "skel_encoder.joint_embed.cnn.0.bn.bias\n",
      "skel_encoder.joint_embed.cnn.1.cnn.weight\n",
      "skel_encoder.joint_embed.cnn.1.cnn.bias\n",
      "skel_encoder.joint_embed.cnn.3.cnn.weight\n",
      "skel_encoder.joint_embed.cnn.3.cnn.bias\n",
      "skel_encoder.dif_embed.cnn.0.bn.weight\n",
      "skel_encoder.dif_embed.cnn.0.bn.bias\n",
      "skel_encoder.dif_embed.cnn.1.cnn.weight\n",
      "skel_encoder.dif_embed.cnn.1.cnn.bias\n",
      "skel_encoder.dif_embed.cnn.3.cnn.weight\n",
      "skel_encoder.dif_embed.cnn.3.cnn.bias\n",
      "skel_encoder.cnn.cnn1.weight\n",
      "skel_encoder.cnn.cnn1.bias\n",
      "skel_encoder.cnn.bn1.weight\n",
      "skel_encoder.cnn.bn1.bias\n",
      "skel_encoder.cnn.cnn2.weight\n",
      "skel_encoder.cnn.cnn2.bias\n",
      "skel_encoder.cnn.bn2.weight\n",
      "skel_encoder.cnn.bn2.bias\n",
      "skel_encoder.compute_g1.g1.cnn.weight\n",
      "skel_encoder.compute_g1.g1.cnn.bias\n",
      "skel_encoder.compute_g1.g2.cnn.weight\n",
      "skel_encoder.compute_g1.g2.cnn.bias\n",
      "skel_encoder.gcn1.bn.weight\n",
      "skel_encoder.gcn1.bn.bias\n",
      "skel_encoder.gcn1.w.cnn.weight\n",
      "skel_encoder.gcn1.w1.cnn.weight\n",
      "skel_encoder.gcn1.w1.cnn.bias\n",
      "skel_encoder.gcn2.bn.weight\n",
      "skel_encoder.gcn2.bn.bias\n",
      "skel_encoder.gcn2.w.cnn.weight\n",
      "skel_encoder.gcn2.w1.cnn.weight\n",
      "skel_encoder.gcn2.w1.cnn.bias\n",
      "skel_encoder.gcn3.bn.weight\n",
      "skel_encoder.gcn3.bn.bias\n",
      "skel_encoder.gcn3.w.cnn.weight\n",
      "skel_encoder.gcn3.w1.cnn.weight\n",
      "skel_encoder.gcn3.w1.cnn.bias\n",
      "skel_decoder.lstm.weight_ih_l0\n",
      "skel_decoder.lstm.weight_hh_l0\n",
      "skel_decoder.lstm.bias_ih_l0\n",
      "skel_decoder.lstm.bias_hh_l0\n",
      "skel_decoder.lstm.weight_hr_l0\n",
      "skel_decoder.lstm.weight_ih_l0_reverse\n",
      "skel_decoder.lstm.weight_hh_l0_reverse\n",
      "skel_decoder.lstm.bias_ih_l0_reverse\n",
      "skel_decoder.lstm.bias_hh_l0_reverse\n",
      "skel_decoder.lstm.weight_hr_l0_reverse\n",
      "skel_decoder.lstm.weight_ih_l1\n",
      "skel_decoder.lstm.weight_hh_l1\n",
      "skel_decoder.lstm.bias_ih_l1\n",
      "skel_decoder.lstm.bias_hh_l1\n",
      "skel_decoder.lstm.weight_hr_l1\n",
      "skel_decoder.lstm.weight_ih_l1_reverse\n",
      "skel_decoder.lstm.weight_hh_l1_reverse\n",
      "skel_decoder.lstm.bias_ih_l1_reverse\n",
      "skel_decoder.lstm.bias_hh_l1_reverse\n",
      "skel_decoder.lstm.weight_hr_l1_reverse\n",
      "fc_head.hidden.weight\n",
      "fc_head.hidden.bias\n",
      "fc_head.output.weight\n",
      "fc_head.output.bias\n",
      "lxmert_xlayer.visual_attention.att.query.weight\n",
      "lxmert_xlayer.visual_attention.att.query.bias\n",
      "lxmert_xlayer.visual_attention.att.key.weight\n",
      "lxmert_xlayer.visual_attention.att.key.bias\n",
      "lxmert_xlayer.visual_attention.att.value.weight\n",
      "lxmert_xlayer.visual_attention.att.value.bias\n",
      "lxmert_xlayer.visual_attention.output.dense.weight\n",
      "lxmert_xlayer.visual_attention.output.dense.bias\n",
      "lxmert_xlayer.visual_attention.output.LayerNorm.weight\n",
      "lxmert_xlayer.visual_attention.output.LayerNorm.bias\n",
      "lxmert_xlayer.lang_self_att.self.query.weight\n",
      "lxmert_xlayer.lang_self_att.self.query.bias\n",
      "lxmert_xlayer.lang_self_att.self.key.weight\n",
      "lxmert_xlayer.lang_self_att.self.key.bias\n",
      "lxmert_xlayer.lang_self_att.self.value.weight\n",
      "lxmert_xlayer.lang_self_att.self.value.bias\n",
      "lxmert_xlayer.lang_self_att.output.dense.weight\n",
      "lxmert_xlayer.lang_self_att.output.dense.bias\n",
      "lxmert_xlayer.lang_self_att.output.LayerNorm.weight\n",
      "lxmert_xlayer.lang_self_att.output.LayerNorm.bias\n",
      "lxmert_xlayer.visn_self_att.self.query.weight\n",
      "lxmert_xlayer.visn_self_att.self.query.bias\n",
      "lxmert_xlayer.visn_self_att.self.key.weight\n",
      "lxmert_xlayer.visn_self_att.self.key.bias\n",
      "lxmert_xlayer.visn_self_att.self.value.weight\n",
      "lxmert_xlayer.visn_self_att.self.value.bias\n",
      "lxmert_xlayer.visn_self_att.output.dense.weight\n",
      "lxmert_xlayer.visn_self_att.output.dense.bias\n",
      "lxmert_xlayer.visn_self_att.output.LayerNorm.weight\n",
      "lxmert_xlayer.visn_self_att.output.LayerNorm.bias\n",
      "lxmert_xlayer.lang_inter.dense.weight\n",
      "lxmert_xlayer.lang_inter.dense.bias\n",
      "lxmert_xlayer.lang_output.dense.weight\n",
      "lxmert_xlayer.lang_output.dense.bias\n",
      "lxmert_xlayer.lang_output.LayerNorm.weight\n",
      "lxmert_xlayer.lang_output.LayerNorm.bias\n",
      "lxmert_xlayer.visn_inter.dense.weight\n",
      "lxmert_xlayer.visn_inter.dense.bias\n",
      "lxmert_xlayer.visn_output.dense.weight\n",
      "lxmert_xlayer.visn_output.dense.bias\n",
      "lxmert_xlayer.visn_output.LayerNorm.weight\n",
      "lxmert_xlayer.visn_output.LayerNorm.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in base_model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
