{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from scipy.signal import resample\n",
    "from glob import glob \n",
    "import scipy.io \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PAMAP2Reader(object):\n",
    "    def __init__(self, root_path):\n",
    "        self.root_path = root_path\n",
    "        self.readPamap2()\n",
    "\n",
    "    def readFile(self, file_path, cols):\n",
    "        all_data = {\"data\": {}, \"target\": {}, 'collection': []}\n",
    "        prev_action = -1\n",
    "        starting = True\n",
    "        # action_seq = []\n",
    "        action_ID = 0\n",
    "\n",
    "        for l in open(file_path).readlines():\n",
    "            s = l.strip().split()\n",
    "            if s[1] != \"0\":\n",
    "                if (prev_action != int(s[1])):\n",
    "                    if not(starting):\n",
    "                        df = pd.DataFrame(action_seq)\n",
    "                        intep_df = df.interpolate(method='linear', limit_direction='backward', axis=0)\n",
    "                        intep_data = intep_df.values \n",
    "                        all_data['data'][action_ID] = np.array(intep_data)\n",
    "                        all_data['target'][action_ID] = prev_action\n",
    "                        action_ID+=1\n",
    "                    action_seq = []\n",
    "                else:\n",
    "                    starting = False\n",
    "                intm_data = s[3:]\n",
    "                data_seq = np.array(intm_data)[cols].astype(np.float16)\n",
    "                # data_seq[np.isnan(data_seq)] = 0\n",
    "                action_seq.append(data_seq)\n",
    "                prev_action = int(s[1])\n",
    "                # print(prev_action)\n",
    "                all_data['collection'].append(data_seq)\n",
    "        else: \n",
    "            if len(action_seq) > 1:\n",
    "                df = pd.DataFrame(action_seq)\n",
    "                intep_df = df.interpolate(method='linear', limit_direction='backward', axis=0)\n",
    "                intep_data = intep_df.values\n",
    "                all_data['data'][action_ID] = np.array(intep_data)\n",
    "                all_data['target'][action_ID] = prev_action\n",
    "        return all_data\n",
    "\n",
    "    def readPamap2Files(self, filelist, cols, labelToId):\n",
    "        data = []\n",
    "        labels = []\n",
    "        collection = []\n",
    "        for i, filename in enumerate(filelist):\n",
    "            print('Reading file %d of %d' % (i+1, len(filelist)))\n",
    "            fpath = os.path.join(self.root_path, filename)\n",
    "            file_data = self.readFile(fpath, cols)\n",
    "            data.extend(list(file_data['data'].values()))\n",
    "            labels.extend(list(file_data['target'].values()))\n",
    "            collection.extend(file_data['collection'])\n",
    "        return np.asarray(data), np.asarray(labels, dtype=int), np.array(collection)\n",
    "\n",
    "    def readPamap2(self):\n",
    "        files = ['subject101.dat', 'subject102.dat','subject103.dat','subject104.dat', 'subject105.dat', 'subject106.dat', 'subject107.dat', 'subject108.dat', 'subject109.dat', 'subject110.dat', 'subject111.dat', 'subject112.dat', 'subject113.dat', 'subject114.dat']\n",
    "            \n",
    "        label_map = [\n",
    "            #(0, 'other'),\n",
    "            (1, 'lying'),\n",
    "            (2, 'sitting'),\n",
    "            (3, 'standing'),\n",
    "            (4, 'walking'),\n",
    "            (5, 'running'),\n",
    "            (6, 'cycling'),\n",
    "            (7, 'Nordic walking'),\n",
    "            (9, 'watching TV'),\n",
    "            (10, 'computer work'),\n",
    "            (11, 'car driving'),\n",
    "            (12, 'ascending stairs'),\n",
    "            (13, 'descending stairs'),\n",
    "            (16, 'vacuum cleaning'),\n",
    "            (17, 'ironing'),\n",
    "            (18, 'folding laundry'),\n",
    "            (19, 'house cleaning'),\n",
    "            (20, 'playing soccer'),\n",
    "            (24, 'rope jumping')\n",
    "        ]\n",
    "        labelToId = {x[0]: i for i, x in enumerate(label_map)}\n",
    "        # print \"label2id=\",labelToId\n",
    "        idToLabel = [x[1] for x in label_map]\n",
    "        # print \"id2label=\",idToLabel\n",
    "        cols = [1,2,3,7,8,9,10,11,12,17,18,19,23,24,25,26,27,28,33,34,35,39,40,41,42,43,44]\n",
    "        self.cols = cols\n",
    "        # print \"cols\",cols\n",
    "        self.data, self.targets, self.all_data = self.readPamap2Files(files, cols, labelToId)\n",
    "        # self.data = self.data[:, :, cols]\n",
    "        # print(self.data)\n",
    "        # nan_perc = np.isnan(self.data).astype(int).mean()\n",
    "        # print(\"null value percentage \", nan_perc)\n",
    "        # f = lambda x: labelToId[x]\n",
    "        self.targets = np.array([labelToId[i] for i in list(self.targets)])\n",
    "        self.label_map = label_map\n",
    "        self.idToLabel = idToLabel\n",
    "        # return data, idToLabel\n",
    "\n",
    "    def resample(self, signal, freq=10):\n",
    "        step_size = int(100/freq)\n",
    "        seq_len, _ = signal.shape \n",
    "        resample_indx = np.arange(0, seq_len, step_size)\n",
    "        resampled_sig = signal[resample_indx, :]\n",
    "        return resampled_sig\n",
    "\n",
    "    def windowing(self, signal, window_len, overlap):\n",
    "        seq_len = int(window_len*100) # 100Hz compensation \n",
    "        overlap_len = int(overlap*100) # 100Hz\n",
    "        l, _ = signal.shape\n",
    "        if l > seq_len:\n",
    "            windowing_points = np.arange(start=0, stop=l-seq_len, step=seq_len-overlap_len, dtype=int)[:-1]\n",
    "\n",
    "            windows = [signal[p:p+seq_len, :] for p in windowing_points]\n",
    "        else:\n",
    "            windows = []\n",
    "        return windows\n",
    "\n",
    "    def resampling(self, data, targets, window_size, window_overlap, resample_freq):\n",
    "        assert len(data) == len(targets), \"# action data & # action labels are not matching\"\n",
    "        all_data, all_ids, all_labels = [], [], []\n",
    "        for i, d in enumerate(data):\n",
    "            # print(\">>>>>>>>>>>>>>>  \", np.isnan(d).mean())\n",
    "            label = targets[i]\n",
    "            windows = self.windowing(d, window_size, window_overlap)\n",
    "            for w in windows:\n",
    "                # print(np.isnan(w).mean(), label, i)\n",
    "                resample_sig = self.resample(w, resample_freq)\n",
    "                # print(np.isnan(resample_sig).mean(), label, i)\n",
    "                all_data.append(resample_sig)\n",
    "                all_ids.append(i+1)\n",
    "                all_labels.append(label)\n",
    "\n",
    "        return all_data, all_ids, all_labels\n",
    "\n",
    "    def generate(self, unseen_classes, window_size=5.21, window_overlap=1, resample_freq=10, smoothing=False, normalize=False, seen_ratio=0.2, unseen_ratio=0.8):\n",
    "        \n",
    "        def smooth(x, window_len=11, window='hanning'):\n",
    "            if x.ndim != 1:\n",
    "                    raise Exception('smooth only accepts 1 dimension arrays.')\n",
    "            if x.size < window_len:\n",
    "                    raise Exception(\"Input vector needs to be bigger than window size.\")\n",
    "            if window_len<3:\n",
    "                    return x\n",
    "            if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "                    raise Exception(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "            s=np.r_[2*x[0]-x[window_len-1::-1],x,2*x[-1]-x[-1:-window_len:-1]]\n",
    "            if window == 'flat': #moving average\n",
    "                    w=np.ones(window_len,'d')\n",
    "            else:  \n",
    "                    w=eval('np.'+window+'(window_len)')\n",
    "            y=np.convolve(w/w.sum(),s,mode='same')\n",
    "            return y[window_len:-window_len+1]\n",
    "\n",
    "        # assert all([i in list(self.label_map.keys()) for i in unseen_classes]), \"Unknown Class label!\"\n",
    "        seen_classes = [i for i in range(len(self.idToLabel)) if i not in unseen_classes]\n",
    "        unseen_mask = np.in1d(self.targets, unseen_classes)\n",
    "\n",
    "        # build seen dataset \n",
    "        seen_data = self.data[np.invert(unseen_mask)]\n",
    "        seen_targets = self.targets[np.invert(unseen_mask)]\n",
    "\n",
    "        # build unseen dataset\n",
    "        unseen_data = self.data[unseen_mask]\n",
    "        unseen_targets = self.targets[unseen_mask]\n",
    "\n",
    "        # resampling seen and unseen datasets \n",
    "        seen_data, seen_ids, seen_targets = self.resampling(seen_data, seen_targets, window_size, window_overlap, resample_freq)\n",
    "        unseen_data, unseen_ids, unseen_targets = self.resampling(unseen_data, unseen_targets, window_size, window_overlap, resample_freq)\n",
    "\n",
    "        seen_data, seen_targets = np.array(seen_data), np.array(seen_targets)\n",
    "        unseen_data, unseen_targets = np.array(unseen_data), np.array(unseen_targets)\n",
    "\n",
    "        if normalize:\n",
    "            a, b, nft = seen_data.shape \n",
    "            intm_sdata = seen_data.reshape((-1, nft))\n",
    "            intm_udata = unseen_data.reshape((-1, nft))\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            norm_sdata = scaler.fit_transform(intm_sdata)\n",
    "            norm_udata = scaler.transform(intm_udata)\n",
    "\n",
    "            seen_data = norm_sdata.reshape(seen_data.shape)\n",
    "            unseen_data = norm_udata.reshape(unseen_data.shape)\n",
    "\n",
    "        if smoothing:\n",
    "            seen_data = np.apply_along_axis(smooth, axis=1, arr=seen_data)\n",
    "            unseen_data = np.apply_along_axis(smooth, axis=1, arr=unseen_data)\n",
    "        # train-val split\n",
    "        seen_index = list(range(len(seen_targets)))\n",
    "        random.shuffle(seen_index)\n",
    "        split_point = int((1-seen_ratio)*len(seen_index))\n",
    "        fst_index, sec_index = seen_index[:split_point], seen_index[split_point:]\n",
    "        # print(type(fst_index), type(sec_index), type(seen_data), type(seen_targets))\n",
    "        X_seen_train, X_seen_val, y_seen_train, y_seen_val = seen_data[fst_index,:], seen_data[sec_index,:], seen_targets[fst_index], seen_targets[sec_index]\n",
    "        \n",
    "\n",
    "        data = {'train': {\n",
    "                        'X': X_seen_train,\n",
    "                        'y': y_seen_train\n",
    "                        },\n",
    "                'eval-seen':{\n",
    "                        'X': X_seen_val,\n",
    "                        'y': y_seen_val\n",
    "                        },\n",
    "                'test': {\n",
    "                        'X': unseen_data,\n",
    "                        'y': unseen_targets\n",
    "                        },\n",
    "                'seen_classes': seen_classes,\n",
    "                'unseen_classes': unseen_classes\n",
    "                }\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = np.random.rand(100, 21)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.min(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_max = sample.max(axis=0)\n",
    "feat_min = sample.min(axis=0)\n",
    "# min-max normalized feats. \n",
    "norm_feat = (sample-feat_min)/(feat_max-feat_min)\n",
    "norm_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_feat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 20, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resamples = sample.reshape(5, -1, 21)\n",
    "resamples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resample_means = resamples.mean(axis=0)\n",
    "resample_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 21)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resample_stds = resamples.std(axis=0)\n",
    "resample_stds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_resample = np.vstack([resample_means, resample_stds]).reshape((-1,),order='F')\n",
    "full_resample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PAMAP2ReaderV2(object):\n",
    "    def __init__(self, root_path):\n",
    "        self.root_path = root_path\n",
    "        self.readPamap2()\n",
    "\n",
    "    def readFile(self, file_path, cols):\n",
    "        all_data = {\"data\": {}, \"target\": {}, 'collection': []}\n",
    "        prev_action = -1\n",
    "        starting = True\n",
    "        # action_seq = []\n",
    "        action_ID = 0\n",
    "\n",
    "        for l in open(file_path).readlines():\n",
    "            s = l.strip().split()\n",
    "            if s[1] != \"0\":\n",
    "                if (prev_action != int(s[1])):\n",
    "                    if not(starting):\n",
    "                        df = pd.DataFrame(action_seq)\n",
    "                        intep_df = df.interpolate(method='linear', limit_direction='backward', axis=0)\n",
    "                        intep_data = intep_df.values \n",
    "                        all_data['data'][action_ID] = np.array(intep_data)\n",
    "                        all_data['target'][action_ID] = prev_action\n",
    "                        action_ID+=1\n",
    "                    action_seq = []\n",
    "                else:\n",
    "                    starting = False\n",
    "                intm_data = s[3:]\n",
    "                data_seq = np.array(intm_data)[cols].astype(np.float16)\n",
    "                # data_seq[np.isnan(data_seq)] = 0\n",
    "                action_seq.append(data_seq)\n",
    "                prev_action = int(s[1])\n",
    "                # print(prev_action)\n",
    "                all_data['collection'].append(data_seq)\n",
    "        else: \n",
    "            if len(action_seq) > 1:\n",
    "                df = pd.DataFrame(action_seq)\n",
    "                intep_df = df.interpolate(method='linear', limit_direction='backward', axis=0)\n",
    "                intep_data = intep_df.values\n",
    "                all_data['data'][action_ID] = np.array(intep_data)\n",
    "                all_data['target'][action_ID] = prev_action\n",
    "        return all_data\n",
    "\n",
    "    def readPamap2Files(self, filelist, cols, labelToId):\n",
    "        data = []\n",
    "        labels = []\n",
    "        collection = []\n",
    "        for i, filename in enumerate(filelist):\n",
    "            print('Reading file %d of %d' % (i+1, len(filelist)))\n",
    "            fpath = os.path.join(self.root_path, filename)\n",
    "            file_data = self.readFile(fpath, cols)\n",
    "            data.extend(list(file_data['data'].values()))\n",
    "            labels.extend(list(file_data['target'].values()))\n",
    "            collection.extend(file_data['collection'])\n",
    "        return np.asarray(data), np.asarray(labels, dtype=int), np.array(collection)\n",
    "\n",
    "    def readPamap2(self):\n",
    "        files = ['subject101.dat', 'subject102.dat','subject103.dat','subject104.dat', 'subject105.dat', 'subject106.dat', 'subject107.dat', 'subject108.dat', 'subject109.dat', 'subject110.dat', 'subject111.dat', 'subject112.dat', 'subject113.dat', 'subject114.dat']\n",
    "            \n",
    "        label_map = [\n",
    "            #(0, 'other'),\n",
    "            (1, 'lying'),\n",
    "            (2, 'sitting'),\n",
    "            (3, 'standing'),\n",
    "            (4, 'walking'),\n",
    "            (5, 'running'),\n",
    "            (6, 'cycling'),\n",
    "            (7, 'Nordic walking'),\n",
    "            (9, 'watching TV'),\n",
    "            (10, 'computer work'),\n",
    "            (11, 'car driving'),\n",
    "            (12, 'ascending stairs'),\n",
    "            (13, 'descending stairs'),\n",
    "            (16, 'vacuum cleaning'),\n",
    "            (17, 'ironing'),\n",
    "            (18, 'folding laundry'),\n",
    "            (19, 'house cleaning'),\n",
    "            (20, 'playing soccer'),\n",
    "            (24, 'rope jumping')\n",
    "        ]\n",
    "        labelToId = {x[0]: i for i, x in enumerate(label_map)}\n",
    "        # print \"label2id=\",labelToId\n",
    "        idToLabel = [x[1] for x in label_map]\n",
    "        # print \"id2label=\",idToLabel\n",
    "        cols = [1,2,3,7,8,9,10,11,12,17,18,19,23,24,25,26,27,28,33,34,35,39,40,41,42,43,44]\n",
    "        self.cols = cols\n",
    "        # print \"cols\",cols\n",
    "        self.data, self.targets, self.all_data = self.readPamap2Files(files, cols, labelToId)\n",
    "        # self.data = self.data[:, :, cols]\n",
    "        # print(self.data)\n",
    "        # nan_perc = np.isnan(self.data).astype(int).mean()\n",
    "        # print(\"null value percentage \", nan_perc)\n",
    "        # f = lambda x: labelToId[x]\n",
    "        self.targets = np.array([labelToId[i] for i in list(self.targets)])\n",
    "        self.label_map = label_map\n",
    "        self.idToLabel = idToLabel\n",
    "        # return data, idToLabel\n",
    "\n",
    "    def aggregate(self, signal, width):\n",
    "        a,b = signal.shape\n",
    "        resamples = signal.reshape((width, -1, b))\n",
    "        means = resamples.astype(np.float64).mean(axis=0)\n",
    "        stds = resamples.astype(np.float64).std(axis=0)\n",
    "        mergered = np.hstack((means,stds))\n",
    "        # print(signal.shape, means.shape, stds.shape, mergered.shape)\n",
    "        return mergered\n",
    "\n",
    "    def windowing(self, signal, window_len, overlap):\n",
    "        seq_len = int(window_len*100) # 100Hz compensation \n",
    "        overlap_len = int(overlap*100) # 100Hz\n",
    "        l, _ = signal.shape\n",
    "        if l > seq_len:\n",
    "            windowing_points = np.arange(start=0, stop=l-seq_len, step=seq_len-overlap_len, dtype=int)[:-1]\n",
    "\n",
    "            windows = [signal[p:p+seq_len, :] for p in windowing_points]\n",
    "        else:\n",
    "            windows = []\n",
    "        return windows\n",
    "\n",
    "    def resampling(self, data, targets, window_size, window_overlap, resample_freq):\n",
    "        assert len(data) == len(targets), \"# action data & # action labels are not matching\"\n",
    "        all_data, all_ids, all_labels = [], [], []\n",
    "        for i, d in enumerate(data):\n",
    "            # print(\">>>>>>>>>>>>>>>  \", np.isnan(d).mean())\n",
    "            label = targets[i]\n",
    "            windows = self.windowing(d, window_size, window_overlap)\n",
    "            for w in windows:\n",
    "                # print(np.isnan(w).mean(), label, i)\n",
    "                resample_sig = self.aggregate(w, resample_freq)\n",
    "                # print(np.isnan(resample_sig).mean(), label, i)\n",
    "                all_data.append(resample_sig)\n",
    "                all_ids.append(i+1)\n",
    "                all_labels.append(label)\n",
    "\n",
    "        return all_data, all_ids, all_labels\n",
    "\n",
    "    def generate(self, unseen_classes, window_size=5.21, window_overlap=1, resample_freq=10, smoothing=False, normalize=False, seen_ratio=0.2, unseen_ratio=0.8):\n",
    "        \n",
    "        def smooth(x, window_len=11, window='hanning'):\n",
    "            if x.ndim != 1:\n",
    "                    raise Exception('smooth only accepts 1 dimension arrays.')\n",
    "            if x.size < window_len:\n",
    "                    raise Exception(\"Input vector needs to be bigger than window size.\")\n",
    "            if window_len<3:\n",
    "                    return x\n",
    "            if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "                    raise Exception(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "            s=np.r_[2*x[0]-x[window_len-1::-1],x,2*x[-1]-x[-1:-window_len:-1]]\n",
    "            if window == 'flat': #moving average\n",
    "                    w=np.ones(window_len,'d')\n",
    "            else:  \n",
    "                    w=eval('np.'+window+'(window_len)')\n",
    "            y=np.convolve(w/w.sum(),s,mode='same')\n",
    "            return y[window_len:-window_len+1]\n",
    "\n",
    "        # assert all([i in list(self.label_map.keys()) for i in unseen_classes]), \"Unknown Class label!\"\n",
    "        seen_classes = [i for i in range(len(self.idToLabel)) if i not in unseen_classes]\n",
    "        unseen_mask = np.in1d(self.targets, unseen_classes)\n",
    "\n",
    "        # build seen dataset \n",
    "        seen_data = self.data[np.invert(unseen_mask)]\n",
    "        seen_targets = self.targets[np.invert(unseen_mask)]\n",
    "\n",
    "        # build unseen dataset\n",
    "        unseen_data = self.data[unseen_mask]\n",
    "        unseen_targets = self.targets[unseen_mask]\n",
    "\n",
    "        # resampling seen and unseen datasets \n",
    "        seen_data, seen_ids, seen_targets = self.resampling(seen_data, seen_targets, window_size, window_overlap, resample_freq)\n",
    "        unseen_data, unseen_ids, unseen_targets = self.resampling(unseen_data, unseen_targets, window_size, window_overlap, resample_freq)\n",
    "\n",
    "        seen_data, seen_targets = np.array(seen_data), np.array(seen_targets)\n",
    "        unseen_data, unseen_targets = np.array(unseen_data), np.array(unseen_targets)\n",
    "\n",
    "        if normalize:\n",
    "            a, b, nft = seen_data.shape \n",
    "            intm_sdata = seen_data.reshape((-1, nft))\n",
    "            intm_udata = unseen_data.reshape((-1, nft))\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            norm_sdata = scaler.fit_transform(intm_sdata)\n",
    "            norm_udata = scaler.transform(intm_udata)\n",
    "\n",
    "            seen_data = norm_sdata.reshape(seen_data.shape)\n",
    "            unseen_data = norm_udata.reshape(unseen_data.shape)\n",
    "\n",
    "        if smoothing:\n",
    "            seen_data = np.apply_along_axis(smooth, axis=1, arr=seen_data)\n",
    "            unseen_data = np.apply_along_axis(smooth, axis=1, arr=unseen_data)\n",
    "\n",
    "        # train-val split\n",
    "        seen_index = list(range(len(seen_targets)))\n",
    "        random.shuffle(seen_index)\n",
    "        split_point = int((1-seen_ratio)*len(seen_index))\n",
    "        fst_index, sec_index = seen_index[:split_point], seen_index[split_point:]\n",
    "        # print(type(fst_index), type(sec_index), type(seen_data), type(seen_targets))\n",
    "        X_seen_train, X_seen_val, y_seen_train, y_seen_val = seen_data[fst_index,:], seen_data[sec_index,:], seen_targets[fst_index], seen_targets[sec_index]\n",
    "        \n",
    "\n",
    "        data = {'train': {\n",
    "                        'X': X_seen_train,\n",
    "                        'y': y_seen_train\n",
    "                        },\n",
    "                'eval-seen':{\n",
    "                        'X': X_seen_val,\n",
    "                        'y': y_seen_val\n",
    "                        },\n",
    "                'test': {\n",
    "                        'X': unseen_data,\n",
    "                        'y': unseen_targets\n",
    "                        },\n",
    "                'seen_classes': seen_classes,\n",
    "                'unseen_classes': unseen_classes\n",
    "                }\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvts_trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccc35149ad8fa032444ebff1245e6ef176e6c1ce3af8dec48e3374f21a6b0f27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
