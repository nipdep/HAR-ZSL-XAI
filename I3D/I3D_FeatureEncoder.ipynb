{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iH7043iKpWSx",
    "outputId": "cae29ecf-1d36-4afe-e849-fb91f24c08f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Mon_Sep_13_20:11:50_Pacific_Daylight_Time_2021\n",
      "Cuda compilation tools, release 11.5, V11.5.50\n",
      "Build cuda_11.5.r11.5/compiler.30411180_0\n",
      "gcc (MinGW.org GCC-6.3.0-1) 6.3.0\n",
      "Copyright (C) 2016 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "# Check nvcc version\n",
    "!nvcc -V\n",
    "# Check GCC version\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMAction2 installation\n",
    "import mmaction\n",
    "print(mmaction.__version__)\n",
    "\n",
    "# Check MMCV installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BC6u24fkpaL8",
    "outputId": "d060b4af-2523-4a4a-974f-3c52216aede4"
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu111 True\n",
      "0.24.1\n",
      "11.1\n",
      "MSVC 192829924\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from mmaction.apis import init_recognizer\n",
    "\n",
    "# Choose to use a config and initialize the recognizer\n",
    "config = '../mmaction2/configs/recognition/tsn/tsn_r50_video_inference_1x1x3_100e_kinetics400_rgb.py'\n",
    "# Setup a checkpoint file to load\n",
    "checkpoint = 'checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
    "# Initialize the recognizer\n",
    "model = init_recognizer(config, checkpoint, device='cuda:0')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s2er4P2npfo5",
    "outputId": "82a9f825-8086-48fb-fc5c-e699f83a097a"
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vs4LW_noJF_Q",
    "outputId": "86868e25-84b2-48d8-dd02-cd276a58ed9a"
   },
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "Recognizer2D(\n  (backbone): ResNet(\n    (conv1): ConvModule(\n      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (activate): ReLU(inplace=True)\n    )\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n        (downsample): ConvModule(\n          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n        (downsample): ConvModule(\n          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n        (downsample): ConvModule(\n          (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n        (downsample): ConvModule(\n          (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): ConvModule(\n          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv2): ConvModule(\n          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (activate): ReLU(inplace=True)\n        )\n        (conv3): ConvModule(\n          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (relu): ReLU(inplace=True)\n      )\n    )\n  )\n  (cls_head): TSNHead(\n    (loss_cls): CrossEntropyLoss()\n    (consensus): AvgConsensus()\n    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (dropout): Dropout(p=0.4, inplace=False)\n    (fc_cls): Linear(in_features=2048, out_features=400, bias=True)\n  )\n)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.cls_head.fc_cls"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pfvi2SPiJF2E",
    "outputId": "0fa33767-10aa-411b-c5e4-10e2ea0fc9b6"
   },
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=2048, out_features=400, bias=True)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import re\n",
    "import warnings\n",
    "from operator import itemgetter\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import torch\n",
    "from mmcv.parallel import collate, scatter\n",
    "from mmcv.runner import load_checkpoint\n",
    "\n",
    "from mmaction.core import OutputHook\n",
    "from mmaction.datasets.pipelines import Compose\n",
    "from mmaction.models import build_recognizer"
   ],
   "metadata": {
    "id": "_JKfEgHlLmDo"
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def inference_recognizer(model, video, outputs=None, as_tensor=True, **kwargs):\n",
    "    \"\"\"Inference a video with the recognizer.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The loaded recognizer.\n",
    "        video (str | dict | ndarray): The video file path / url or the\n",
    "            rawframes directory path / results dictionary (the input of\n",
    "            pipeline) / a 4D array T x H x W x 3 (The input video).\n",
    "        outputs (list(str) | tuple(str) | str | None) : Names of layers whose\n",
    "            outputs need to be returned, default: None.\n",
    "        as_tensor (bool): Same as that in ``OutputHook``. Default: True.\n",
    "\n",
    "    Returns:\n",
    "        dict[tuple(str, float)]: Top-5 recognition result dict.\n",
    "        dict[torch.tensor | np.ndarray]:\n",
    "            Output feature maps from layers specified in `outputs`.\n",
    "    \"\"\"\n",
    "    if 'use_frames' in kwargs:\n",
    "        warnings.warn('The argument `use_frames` is deprecated PR #1191. '\n",
    "                      'Now you can use models trained with frames or videos '\n",
    "                      'arbitrarily. ')\n",
    "    if 'label_path' in kwargs:\n",
    "        warnings.warn('The argument `use_frames` is deprecated PR #1191. '\n",
    "                      'Now the label file is not needed in '\n",
    "                      'inference_recognizer. ')\n",
    "\n",
    "    input_flag = None\n",
    "    if isinstance(video, dict):\n",
    "        input_flag = 'dict'\n",
    "    elif isinstance(video, np.ndarray):\n",
    "        assert len(video.shape) == 4, 'The shape should be T x H x W x C'\n",
    "        input_flag = 'array'\n",
    "    elif isinstance(video, str) and video.startswith('http'):\n",
    "        input_flag = 'video'\n",
    "    elif isinstance(video, str) and osp.exists(video):\n",
    "        if osp.isfile(video):\n",
    "            if video.endswith('.npy'):\n",
    "                input_flag = 'audio'\n",
    "            else:\n",
    "                input_flag = 'video'\n",
    "        if osp.isdir(video):\n",
    "            input_flag = 'rawframes'\n",
    "    else:\n",
    "        raise RuntimeError('The type of argument video is not supported: '\n",
    "                           f'{type(video)}')\n",
    "\n",
    "    if isinstance(outputs, str):\n",
    "        outputs = (outputs, )\n",
    "    assert outputs is None or isinstance(outputs, (tuple, list))\n",
    "\n",
    "    cfg = model.cfg\n",
    "    device = next(model.parameters()).device  # model device\n",
    "    # build the data pipeline\n",
    "    test_pipeline = cfg.data.test.pipeline\n",
    "    # Alter data pipelines & prepare inputs\n",
    "    if input_flag == 'dict':\n",
    "        data = video\n",
    "    if input_flag == 'array':\n",
    "        modality_map = {2: 'Flow', 3: 'RGB'}\n",
    "        modality = modality_map.get(video.shape[-1])\n",
    "        data = dict(\n",
    "            total_frames=video.shape[0],\n",
    "            label=-1,\n",
    "            start_index=0,\n",
    "            array=video,\n",
    "            modality=modality)\n",
    "        for i in range(len(test_pipeline)):\n",
    "            if 'Decode' in test_pipeline[i]['type']:\n",
    "                test_pipeline[i] = dict(type='ArrayDecode')\n",
    "        test_pipeline = [x for x in test_pipeline if 'Init' not in x['type']]\n",
    "    if input_flag == 'video':\n",
    "        data = dict(filename=video, label=-1, start_index=0, modality='RGB')\n",
    "        if 'Init' not in test_pipeline[0]['type']:\n",
    "            test_pipeline = [dict(type='OpenCVInit')] + test_pipeline\n",
    "        else:\n",
    "            test_pipeline[0] = dict(type='OpenCVInit')\n",
    "        for i in range(len(test_pipeline)):\n",
    "            if 'Decode' in test_pipeline[i]['type']:\n",
    "                test_pipeline[i] = dict(type='OpenCVDecode')\n",
    "    if input_flag == 'rawframes':\n",
    "        filename_tmpl = cfg.data.test.get('filename_tmpl', 'img_{:05}.jpg')\n",
    "        modality = cfg.data.test.get('modality', 'RGB')\n",
    "        start_index = cfg.data.test.get('start_index', 1)\n",
    "\n",
    "        # count the number of frames that match the format of `filename_tmpl`\n",
    "        # RGB pattern example: img_{:05}.jpg -> ^img_\\d+.jpg$\n",
    "        # Flow patteren example: {}_{:05d}.jpg -> ^x_\\d+.jpg$\n",
    "        pattern = f'^{filename_tmpl}$'\n",
    "        if modality == 'Flow':\n",
    "            pattern = pattern.replace('{}', 'x')\n",
    "        pattern = pattern.replace(\n",
    "            pattern[pattern.find('{'):pattern.find('}') + 1], '\\\\d+')\n",
    "        total_frames = len(\n",
    "            list(\n",
    "                filter(lambda x: re.match(pattern, x) is not None,\n",
    "                       os.listdir(video))))\n",
    "        data = dict(\n",
    "            frame_dir=video,\n",
    "            total_frames=total_frames,\n",
    "            label=-1,\n",
    "            start_index=start_index,\n",
    "            filename_tmpl=filename_tmpl,\n",
    "            modality=modality)\n",
    "        if 'Init' in test_pipeline[0]['type']:\n",
    "            test_pipeline = test_pipeline[1:]\n",
    "        for i in range(len(test_pipeline)):\n",
    "            if 'Decode' in test_pipeline[i]['type']:\n",
    "                test_pipeline[i] = dict(type='RawFrameDecode')\n",
    "    if input_flag == 'audio':\n",
    "        data = dict(\n",
    "            audio_path=video,\n",
    "            total_frames=len(np.load(video)),\n",
    "            start_index=cfg.data.test.get('start_index', 1),\n",
    "            label=-1)\n",
    "\n",
    "    test_pipeline = Compose(test_pipeline)\n",
    "    data = test_pipeline(data)\n",
    "    data = collate([data], samples_per_gpu=1)\n",
    "\n",
    "    if next(model.parameters()).is_cuda:\n",
    "        # scatter to specified GPU\n",
    "        data = scatter(data, [device])[0]\n",
    "\n",
    "    # forward the model\n",
    "    # with OutputHook(model, outputs=outputs, as_tensor=as_tensor) as h:\n",
    "    # model.cls_head.register_forward_hook(get_activation('dropout'))\n",
    "    # with torch.no_grad():\n",
    "    #     result = model(return_loss=False, **data)\n",
    "    with torch.no_grad():\n",
    "        my_output = None\n",
    "        \n",
    "        def my_hook(module_, input_, output_):\n",
    "            nonlocal my_output\n",
    "            my_output = output_\n",
    "\n",
    "        #a_hook = model.backbone.layer3.register_forward_hook(my_hook)\n",
    "        a_hook = model.cls_head.dropout.register_forward_hook(my_hook)\n",
    "        model(return_loss=False, **data)\n",
    "        a_hook.remove()\n",
    "        # return my_output\n",
    "    #     returned_features = h.layer_outputs if outputs else None\n",
    "\n",
    "    # num_classes = scores.shape[-1]\n",
    "    # score_tuples = tuple(zip(range(num_classes), scores))\n",
    "    # score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)\n",
    "\n",
    "    # top5_label = score_sorted[:5]\n",
    "    # if outputs:\n",
    "    #     return top5_label, returned_features\n",
    "    return my_output.squeeze()"
   ],
   "metadata": {
    "id": "s55EEbjSLl5Y"
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Use the recognizer to do inference\n",
    "video = '../data/nipun_video_dataset/PAMAP2_K10_V1/ascending stairs/as9.mp4'\n",
    "label = '../mmaction2/tools/data/kinetics/label_map_k400.txt'\n",
    "results = inference_recognizer(model, video)\n",
    "\n",
    "# print(results)\n",
    "# labels = open(label).readlines()\n",
    "# labels = [x.strip() for x in labels]\n",
    "# results = [(labels[k[0]], k[1]) for k in results]"
   ],
   "metadata": {
    "id": "6HTnYMeCphzh"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "type(results), results.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "erxGMdl-OZ09",
    "outputId": "730be3ce-6306-4301-f1cf-bdd81099fcea"
   },
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Tensor, torch.Size([250, 1024, 14, 14]))"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "id": "t2NRXKdlPqsM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os \n",
    "import glob\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "id": "C1CdnlJVRNzk"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dir_path = '../data/nipun_video_dataset/PAMAP2_K10_V1/'"
   ],
   "metadata": {
    "id": "D64mw7BkQW1Z"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "video_ft_dict = {}\n",
    "for p in tqdm(glob.glob(dir_path+'*/*.mp4',recursive=True)):\n",
    "  action = p.split(os.path.sep)[-2]\n",
    "  ft_vector = inference_recognizer(model, p).cpu().numpy()\n",
    "  try:\n",
    "    video_ft_dict[action].append(ft_vector)\n",
    "  except KeyError:\n",
    "    video_ft_dict[action] = [ft_vector]\n",
    "    \n",
    "\"\"\"\n",
    "for p in glob.glob(dir_path+'*/*.avi',recursive=True):\n",
    "  action = p.split(os.path.sep)[-2]\n",
    "  ft_vector = inference_recognizer(model, p).cpu().numpy()\n",
    "  try:\n",
    "    video_ft_dict[action].append(ft_vector)\n",
    "  except:\n",
    "    video_ft_dict[action] = [ft_vector]\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "id": "4GeTO-MvShBa"
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [15:12<00:00,  5.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"\\nfor p in glob.glob(dir_path+'*/*.avi',recursive=True):\\n  action = p.split(os.path.sep)[-2]\\n  ft_vector = inference_recognizer(model, p).cpu().numpy()\\n  try:\\n    video_ft_dict[action].append(ft_vector)\\n  except:\\n    video_ft_dict[action] = [ft_vector]\\n\""
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "video_ft_dict.keys()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jydh_o8Yr3E",
    "outputId": "e59b8eb8-d266-4519-fff6-c75b6db41216"
   },
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['ascending stairs', 'car driving', 'computer work', 'cycling', 'descending stairs', 'folding laundry', 'house cleaning', 'ironing', 'lying', 'Nordic walking', 'playing soccer', 'rope jumping', 'running', 'sitting', 'standing', 'vacuum cleaning', 'walking', 'watching TV'])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "feat_dict = video_ft_dict"
   ],
   "metadata": {
    "id": "ILS4Rm5SYYUU"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def save_file(feat_d:dict,save_loc:str):\n",
    "    __class = []\n",
    "    __features = []\n",
    "    for k,v in feat_d.items():\n",
    "        for feature in v:\n",
    "            __class.append(k)\n",
    "            __features.append(feature)\n",
    "\n",
    "    __class = np.asarray(__class)\n",
    "    __features = np.asarray(__features)\n",
    "\n",
    "    np.savez(save_loc,activity=__class,features=__features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "save_file(feat_dict,\"../data/I3D/video_feat/PAMAP2_K10_V1/feat_dict.npz\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
