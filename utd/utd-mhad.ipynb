{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy.io \n",
    "from glob import glob \n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataTableOptimizerUpdated(mat_file, key='d_skel'):\n",
    "    our_data = mat_file[key]\n",
    "    datas = []\n",
    "    frame_size = len(our_data[0][0])-1\n",
    "    for each in range(0,frame_size):\n",
    "        data_flatten = our_data[:,:,each].flatten()\n",
    "        data_flatten = data_flatten[np.newaxis]\n",
    "        datas.append(data_flatten)\n",
    "    return datas,frame_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1_s1_t1_skeleton.mat\n"
     ]
    }
   ],
   "source": [
    "path = '../data/UTD-MHAD-mini/a1'\n",
    "for entry in sorted(os.listdir(path)):\n",
    "        if os.path.isfile(os.path.join(path, entry)):\n",
    "                print(entry)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '../data/UTD-MHAD-mini/a1/a1_s1_t1_skeleton.mat'\n",
    "mat = scipy.io.loadmat(fpath)\n",
    "all_data, frame = dataTableOptimizerUpdated(mat_file=mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'d_skel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mg:\\FYP\\Codebases\\IMU_data_descriptor\\utd\\utd-mhad.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fpath \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../data/UTD-MHAD-all/a10_s1_t1_inertial.mat\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mat \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mloadmat(fpath)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m all_data, frame \u001b[39m=\u001b[39m dataTableOptimizerUpdated(mat_file\u001b[39m=\u001b[39;49mmat)\n",
      "\u001b[1;32mg:\\FYP\\Codebases\\IMU_data_descriptor\\utd\\utd-mhad.ipynb Cell 5\u001b[0m in \u001b[0;36mdataTableOptimizerUpdated\u001b[1;34m(mat_file, key)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdataTableOptimizerUpdated\u001b[39m(mat_file, key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39md_skel\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     our_data \u001b[39m=\u001b[39m mat_file[key]\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     datas \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     frame_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(our_data[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'd_skel'"
     ]
    }
   ],
   "source": [
    "fpath = '../data/UTD-MHAD-all/a10_s1_t1_inertial.mat'\n",
    "mat = scipy.io.loadmat(fpath)\n",
    "all_data, frame = dataTableOptimizerUpdated(mat_file=mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'d_skel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mg:\\FYP\\Codebases\\IMU_data_descriptor\\utd\\utd-mhad.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fpath \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../data/UTD-MHAD-Inertial/a10_s1_t1_inertial.mat\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mat \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mloadmat(fpath)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m all_data, frame \u001b[39m=\u001b[39m dataTableOptimizerUpdated(mat_file\u001b[39m=\u001b[39;49mmat)\n",
      "\u001b[1;32mg:\\FYP\\Codebases\\IMU_data_descriptor\\utd\\utd-mhad.ipynb Cell 6\u001b[0m in \u001b[0;36mdataTableOptimizerUpdated\u001b[1;34m(mat_file, key)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdataTableOptimizerUpdated\u001b[39m(mat_file, key\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39md_skel\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     our_data \u001b[39m=\u001b[39m mat_file[key]\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     datas \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/FYP/Codebases/IMU_data_descriptor/utd/utd-mhad.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     frame_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(our_data[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'd_skel'"
     ]
    }
   ],
   "source": [
    "fpath = '../data/UTD-MHAD-Inertial/a10_s1_t1_inertial.mat'\n",
    "mat = scipy.io.loadmat(fpath)\n",
    "all_data, frame = dataTableOptimizerUpdated(mat_file=mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['d_iner'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 6)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['d_iner'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3, 63)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['S_K2'][0,0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dict = {}\n",
    "subject_dict = {}\n",
    "frame_list = []\n",
    "all_data = []\n",
    "for p in glob('../data/UTD-MHAD-Inertial/*.mat'):\n",
    "    file_name = p.split('\\\\')[-1]\n",
    "    action, subject, time, _ = file_name.split('_')\n",
    "    try:\n",
    "        action_dict[action] += 1\n",
    "    except:\n",
    "        action_dict[action] = 0\n",
    "\n",
    "    try:\n",
    "        subject_dict[subject] += 1\n",
    "    except:\n",
    "        subject_dict[subject] = 0 \n",
    "    \n",
    "    mat = scipy.io.loadmat(p)['d_iner']\n",
    "    # _, frame = dataTableOptimizerUpdated(mat_file=mat, key='d_iner')\n",
    "    # frame_list.append(frame)\n",
    "    # print(mat.shape)\n",
    "    all_data.append(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155638, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_np = np.vstack(all_data)\n",
    "all_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(all_np).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a10': 31,\n",
       " 'a11': 31,\n",
       " 'a12': 31,\n",
       " 'a13': 31,\n",
       " 'a14': 31,\n",
       " 'a15': 31,\n",
       " 'a16': 31,\n",
       " 'a17': 31,\n",
       " 'a18': 31,\n",
       " 'a19': 31,\n",
       " 'a1': 31,\n",
       " 'a20': 31,\n",
       " 'a21': 31,\n",
       " 'a22': 31,\n",
       " 'a23': 30,\n",
       " 'a24': 31,\n",
       " 'a25': 31,\n",
       " 'a26': 31,\n",
       " 'a27': 30,\n",
       " 'a2': 31,\n",
       " 'a3': 31,\n",
       " 'a4': 31,\n",
       " 'a5': 31,\n",
       " 'a6': 31,\n",
       " 'a7': 31,\n",
       " 'a8': 30,\n",
       " 'a9': 31}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s1': 106,\n",
       " 's2': 107,\n",
       " 's3': 107,\n",
       " 's4': 107,\n",
       " 's5': 107,\n",
       " 's6': 106,\n",
       " 's7': 107,\n",
       " 's8': 106}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 60)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n",
      "(1, 60)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_data)):\n",
    "    print(all_data[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loader(path,chosen_class_number):\n",
    "    full_list = []\n",
    "    for entry in sorted(os.listdir(path)):\n",
    "        if os.path.isfile(os.path.join(path, entry)):\n",
    "            mat = scipy.io.loadmat(path+entry)\n",
    "            all_data, frame = dataTableOptimizerUpdated(mat_file=mat)\n",
    "            full_list.extend(all_data)\n",
    "    #data_ready = dataTableForCluster2(data=full_list,joint_names=joint_names,column_names=col_names,frame=len(full_list))\n",
    "    full_list = np.concatenate(full_list)\n",
    "    data_re = pd.DataFrame(full_list)\n",
    "    data_re['classs'] = np.full((1,len(data_re)),chosen_class_number).T\n",
    "    return data_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action names map \n",
    "action_map = {\n",
    "    1: 'swipe left',\n",
    "    2: 'swipe right',\n",
    "    3: 'wave',\n",
    "    4: 'clap', \n",
    "    5: 'throw',\n",
    "    6: 'arm cross',\n",
    "    7: 'basketball shoot', \n",
    "    8: 'draw x',\n",
    "    9: 'draw circle(clockwise)',\n",
    "    10: 'draw circle(counter clockwise)',\n",
    "    11: 'draw triangle',\n",
    "    12: 'bowling',\n",
    "    13: 'boxing',\n",
    "    14: 'baseball swing',\n",
    "    15: 'tennis swing',\n",
    "    16: 'arm curl',\n",
    "    17: 'tennis serve',\n",
    "    18: 'push', \n",
    "    19: 'knock', \n",
    "    20: 'catch',\n",
    "    21: 'pickup & throw',\n",
    "    22: 'jog',\n",
    "    23: 'walk',\n",
    "    24: 'sit to stand',\n",
    "    25: 'stand to sit',\n",
    "    26: 'lunge',\n",
    "    27: 'squat'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/UTD-MHAD-mini/a'\n",
    "action_dfs = {}\n",
    "for i in range(1, 28):\n",
    "    dir_path = f\"{data_path}{i}/\"\n",
    "    action_dfs[i] = Loader(dir_path, chosen_class_number=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>classs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.045763</td>\n",
       "      <td>0.483985</td>\n",
       "      <td>2.830189</td>\n",
       "      <td>-0.034567</td>\n",
       "      <td>0.299454</td>\n",
       "      <td>2.877040</td>\n",
       "      <td>-0.030579</td>\n",
       "      <td>-0.049345</td>\n",
       "      <td>2.890448</td>\n",
       "      <td>-0.025585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071880</td>\n",
       "      <td>-0.656921</td>\n",
       "      <td>2.910316</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>-1.015431</td>\n",
       "      <td>2.941544</td>\n",
       "      <td>0.098265</td>\n",
       "      <td>-1.081334</td>\n",
       "      <td>2.922989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.045314</td>\n",
       "      <td>0.483987</td>\n",
       "      <td>2.830307</td>\n",
       "      <td>-0.034429</td>\n",
       "      <td>0.299377</td>\n",
       "      <td>2.877029</td>\n",
       "      <td>-0.030435</td>\n",
       "      <td>-0.049361</td>\n",
       "      <td>2.890594</td>\n",
       "      <td>-0.025425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071972</td>\n",
       "      <td>-0.656710</td>\n",
       "      <td>2.910234</td>\n",
       "      <td>0.051715</td>\n",
       "      <td>-1.015332</td>\n",
       "      <td>2.941586</td>\n",
       "      <td>0.092359</td>\n",
       "      <td>-1.076961</td>\n",
       "      <td>2.910020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.044791</td>\n",
       "      <td>0.483999</td>\n",
       "      <td>2.830396</td>\n",
       "      <td>-0.034372</td>\n",
       "      <td>0.299287</td>\n",
       "      <td>2.876948</td>\n",
       "      <td>-0.030323</td>\n",
       "      <td>-0.049369</td>\n",
       "      <td>2.890700</td>\n",
       "      <td>-0.025280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072048</td>\n",
       "      <td>-0.656591</td>\n",
       "      <td>2.910178</td>\n",
       "      <td>0.051751</td>\n",
       "      <td>-1.015237</td>\n",
       "      <td>2.941595</td>\n",
       "      <td>0.088708</td>\n",
       "      <td>-1.074941</td>\n",
       "      <td>2.902789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.044316</td>\n",
       "      <td>0.483995</td>\n",
       "      <td>2.830455</td>\n",
       "      <td>-0.034331</td>\n",
       "      <td>0.299194</td>\n",
       "      <td>2.876836</td>\n",
       "      <td>-0.030229</td>\n",
       "      <td>-0.049374</td>\n",
       "      <td>2.890781</td>\n",
       "      <td>-0.025151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072119</td>\n",
       "      <td>-0.656500</td>\n",
       "      <td>2.910133</td>\n",
       "      <td>0.051771</td>\n",
       "      <td>-1.015162</td>\n",
       "      <td>2.941599</td>\n",
       "      <td>0.086136</td>\n",
       "      <td>-1.073587</td>\n",
       "      <td>2.897764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.043912</td>\n",
       "      <td>0.483994</td>\n",
       "      <td>2.830503</td>\n",
       "      <td>-0.034305</td>\n",
       "      <td>0.299102</td>\n",
       "      <td>2.876704</td>\n",
       "      <td>-0.030150</td>\n",
       "      <td>-0.049374</td>\n",
       "      <td>2.890841</td>\n",
       "      <td>-0.025035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072174</td>\n",
       "      <td>-0.656432</td>\n",
       "      <td>2.910100</td>\n",
       "      <td>0.051791</td>\n",
       "      <td>-1.015113</td>\n",
       "      <td>2.941599</td>\n",
       "      <td>0.085461</td>\n",
       "      <td>-1.073147</td>\n",
       "      <td>2.896265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.045763  0.483985  2.830189 -0.034567  0.299454  2.877040 -0.030579   \n",
       "1 -0.045314  0.483987  2.830307 -0.034429  0.299377  2.877029 -0.030435   \n",
       "2 -0.044791  0.483999  2.830396 -0.034372  0.299287  2.876948 -0.030323   \n",
       "3 -0.044316  0.483995  2.830455 -0.034331  0.299194  2.876836 -0.030229   \n",
       "4 -0.043912  0.483994  2.830503 -0.034305  0.299102  2.876704 -0.030150   \n",
       "\n",
       "          7         8         9  ...        51        52        53        54  \\\n",
       "0 -0.049345  2.890448 -0.025585  ...  0.071880 -0.656921  2.910316  0.051658   \n",
       "1 -0.049361  2.890594 -0.025425  ...  0.071972 -0.656710  2.910234  0.051715   \n",
       "2 -0.049369  2.890700 -0.025280  ...  0.072048 -0.656591  2.910178  0.051751   \n",
       "3 -0.049374  2.890781 -0.025151  ...  0.072119 -0.656500  2.910133  0.051771   \n",
       "4 -0.049374  2.890841 -0.025035  ...  0.072174 -0.656432  2.910100  0.051791   \n",
       "\n",
       "         55        56        57        58        59  classs  \n",
       "0 -1.015431  2.941544  0.098265 -1.081334  2.922989       1  \n",
       "1 -1.015332  2.941586  0.092359 -1.076961  2.910020       1  \n",
       "2 -1.015237  2.941595  0.088708 -1.074941  2.902789       1  \n",
       "3 -1.015162  2.941599  0.086136 -1.073587  2.897764       1  \n",
       "4 -1.015113  2.941599  0.085461 -1.073147  2.896265       1  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_dfs[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UTDReader(object):\n",
    "    def __init__(self, root_path):\n",
    "        self.root_path = root_path\n",
    "        self.readUTD()\n",
    "\n",
    "    def dataTableOptimizerUpdated(self, mat_file):\n",
    "        our_data = mat_file['d_iner']\n",
    "        data = []\n",
    "        frame_size = len(our_data[0][0])-1\n",
    "        for each in range(0,frame_size):\n",
    "            data_flatten = our_data[:,:,each].flatten()\n",
    "            data_flatten = data_flatten\n",
    "            data.append(data_flatten)\n",
    "        return data,frame_size\n",
    "\n",
    "    def readUTDFiles(self, labelToId):\n",
    "        data = []\n",
    "        labels = []\n",
    "        subjects = []\n",
    "        collection = []\n",
    "        \n",
    "        for p in glob(f'{self.root_path}/*.mat'):\n",
    "            file_name = p.split('\\\\')[-1]\n",
    "            action, subject, time, _ = file_name.split('_')\n",
    "            mat = scipy.io.loadmat(p)\n",
    "            # data, frame = self.dataTableOptimizerUpdated(mat_file=mat)\n",
    "            # print('Reading file %d of %d' % (i+1, len(filelist)))\n",
    "            np_data = np.array(mat['d_iner'])\n",
    "            data.append(np_data)\n",
    "            labels.append(int(action.strip('a')))\n",
    "            subjects.append(subject)\n",
    "\n",
    "        # print(f\"data len : {np.array(data).shape}, data 0 shape : {data[0].shape}\")\n",
    "        return np.array(data), np.array(labels, dtype=int), np.array(subjects)\n",
    "\n",
    "    def readUTD(self):\n",
    "           \n",
    "        label_map = [\n",
    "            (1, 'swipe left'),\n",
    "            (2, 'swipe right'),\n",
    "            (3, 'wave'),\n",
    "            (4, 'clap'),\n",
    "            (5, 'throw'),\n",
    "            (6, 'arm cross'),\n",
    "            (7, 'basketball shoot'),\n",
    "            (8, 'draw x'),\n",
    "            (9, 'draw circle(clockwise)'),\n",
    "            (10, 'draw circle(counter clockwise)'),\n",
    "            (11, 'draw triangle'),\n",
    "            (12, 'bowling'),\n",
    "            (13, 'boxing'),\n",
    "            (14, 'baseball swing'),\n",
    "            (15, 'tennis swing'),\n",
    "            (16, 'arm curl'),\n",
    "            (17, 'tennis serve'),\n",
    "            (18, 'push'),\n",
    "            (19, 'knock'),\n",
    "            (20, 'catch'),\n",
    "            (21, 'pickup & throw'),\n",
    "            (22, 'jog'),\n",
    "            (23, 'walk'),\n",
    "            (24, 'sit to stand'),\n",
    "            (25, 'stand to sit'),\n",
    "            (26, 'lunge'),\n",
    "            (27, 'squat')\n",
    "        ]\n",
    "        labelToId = {x[0]: i for i, x in enumerate(label_map)}\n",
    "        # print \"label2id=\",labelToId\n",
    "        idToLabel = [x[1] for x in label_map]\n",
    "\n",
    "        # print \"cols\",cols\n",
    "        self.data, self.targets, self.all_data = self.readUTDFiles(labelToId)\n",
    "        # print(self.data)\n",
    "        # nan_perc = np.isnan(self.data).astype(int).mean()\n",
    "        # print(\"null value percentage \", nan_perc)\n",
    "        # f = lambda x: labelToId[x]\n",
    "        self.targets = np.array([labelToId[i] for i in list(self.targets)])\n",
    "        self.label_map = label_map\n",
    "        self.idToLabel = idToLabel\n",
    "        # return data, idToLabel\n",
    "\n",
    "    def resample(self, signal, freq=10):\n",
    "        step_size = int(100/freq)\n",
    "        seq_len, _ = signal.shape \n",
    "        resample_indx = np.arange(0, seq_len, step_size)\n",
    "        resampled_sig = signal[resample_indx, :]\n",
    "        return resampled_sig\n",
    "\n",
    "    def windowing(self, signal, window_len, overlap):\n",
    "        seq_len = int(window_len*50) # 100Hz compensation \n",
    "        overlap_len = int(overlap*50) # 100Hz\n",
    "        l, _ = signal.shape\n",
    "        if l > seq_len:\n",
    "            windowing_points = np.arange(start=0, stop=l-seq_len, step=seq_len-overlap_len, dtype=int)[:-1]\n",
    "\n",
    "            windows = [signal[p:p+seq_len, :] for p in windowing_points]\n",
    "        else:\n",
    "            windows = []\n",
    "        return windows\n",
    "\n",
    "    def resampling(self, data, targets, window_size, window_overlap, resample_freq):\n",
    "        assert len(data) == len(targets), \"# action data & # action labels are not matching\"\n",
    "        all_data, all_ids, all_labels = [], [], []\n",
    "        for i, d in enumerate(data):\n",
    "            # print(\">>>>>>>>>>>>>>>  \", np.isnan(d).mean())\n",
    "            label = targets[i]\n",
    "            windows = self.windowing(d, window_size, window_overlap)\n",
    "            for w in windows:\n",
    "                # print(np.isnan(w).mean(), label, i)\n",
    "                resample_sig = self.resample(w, resample_freq)\n",
    "                # print(np.isnan(resample_sig).mean(), label, i)\n",
    "                all_data.append(resample_sig)\n",
    "                all_ids.append(i+1)\n",
    "                all_labels.append(label)\n",
    "\n",
    "        return all_data, all_ids, all_labels\n",
    "\n",
    "    def generate(self, unseen_classes, window_size=3, window_overlap=1, resample_freq=10, smoothing=False, normalize=False, seen_ratio=0.2, unseen_ratio=0.8):\n",
    "        \n",
    "        def smooth(x, window_len=11, window='hanning'):\n",
    "            if x.ndim != 1:\n",
    "                    raise Exception('smooth only accepts 1 dimension arrays.')\n",
    "            if x.size < window_len:\n",
    "                    raise Exception(\"Input vector needs to be bigger than window size.\")\n",
    "            if window_len<3:\n",
    "                    return x\n",
    "            if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "                    raise Exception(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "            s=np.r_[2*x[0]-x[window_len-1::-1],x,2*x[-1]-x[-1:-window_len:-1]]\n",
    "            if window == 'flat': #moving average\n",
    "                    w=np.ones(window_len,'d')\n",
    "            else:  \n",
    "                    w=eval('np.'+window+'(window_len)')\n",
    "            y=np.convolve(w/w.sum(),s,mode='same')\n",
    "            return y[window_len:-window_len+1]\n",
    "\n",
    "        # assert all([i in list(self.label_map.keys()) for i in unseen_classes]), \"Unknown Class label!\"\n",
    "        seen_classes = [i for i in range(len(self.idToLabel)) if i not in unseen_classes]\n",
    "        unseen_mask = np.in1d(self.targets, unseen_classes)\n",
    "        \n",
    "        # build seen dataset \n",
    "        seen_data = self.data[np.invert(unseen_mask)]\n",
    "        seen_targets = self.targets[np.invert(unseen_mask)]\n",
    "        print(f\"data shape : {self.data.shape}, seen_data shape : {seen_data.shape}\")\n",
    "        ids, cnts = np.unique(self.targets, return_counts=True)\n",
    "        print({self.idToLabel[ids[e]]: cnts[e] for e in range(len(ids))})\n",
    "\n",
    "        # build unseen dataset\n",
    "        unseen_data = self.data[unseen_mask]\n",
    "        unseen_targets = self.targets[unseen_mask]\n",
    "        \n",
    "        # resampling seen and unseen datasets \n",
    "        seen_data, seen_ids, seen_targets = self.resampling(seen_data, seen_targets, window_size, window_overlap, resample_freq)\n",
    "        unseen_data, unseen_ids, unseen_targets = self.resampling(unseen_data, unseen_targets, window_size, window_overlap, resample_freq)\n",
    "\n",
    "        seen_data, seen_targets = np.array(seen_data), np.array(seen_targets)\n",
    "        unseen_data, unseen_targets = np.array(unseen_data), np.array(unseen_targets)\n",
    "\n",
    "        print(seen_data.shape)\n",
    "\n",
    "        if normalize:\n",
    "            a, b, nft = seen_data.shape \n",
    "            intm_sdata = seen_data.reshape((-1, nft))\n",
    "            intm_udata = unseen_data.reshape((-1, nft))\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            norm_sdata = scaler.fit_transform(intm_sdata)\n",
    "            norm_udata = scaler.transform(intm_udata)\n",
    "\n",
    "            seen_data = norm_sdata.reshape(seen_data.shape)\n",
    "            unseen_data = norm_udata.reshape(unseen_data.shape)\n",
    "\n",
    "        if smoothing:\n",
    "            seen_data = np.apply_along_axis(smooth, axis=1, arr=seen_data)\n",
    "            unseen_data = np.apply_along_axis(smooth, axis=1, arr=unseen_data)\n",
    "        # train-val split\n",
    "        seen_index = list(range(len(seen_targets)))\n",
    "        random.shuffle(seen_index)\n",
    "        split_point = int((1-seen_ratio)*len(seen_index))\n",
    "        fst_index, sec_index = seen_index[:split_point], seen_index[split_point:]\n",
    "        # print(type(fst_index), type(sec_index), type(seen_data), type(seen_targets))\n",
    "        # print(seen_data.shape, fst_index)\n",
    "        X_seen_train, X_seen_val = seen_data[fst_index, ...], seen_data[sec_index, ...]\n",
    "        y_seen_train, y_seen_val = seen_targets[fst_index], seen_targets[sec_index]\n",
    "        \n",
    "\n",
    "        data = {'train': {\n",
    "                        'X': X_seen_train,\n",
    "                        'y': y_seen_train\n",
    "                        },\n",
    "                'eval-seen':{\n",
    "                        'X': X_seen_val,\n",
    "                        'y': y_seen_val\n",
    "                        },\n",
    "                'test': {\n",
    "                        'X': unseen_data,\n",
    "                        'y': unseen_targets\n",
    "                        },\n",
    "                'seen_classes': seen_classes,\n",
    "                'unseen_classes': unseen_classes\n",
    "                }\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deela\\AppData\\Local\\Temp\\ipykernel_22768\\260658175.py:34: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(data), np.array(labels, dtype=int), np.array(subjects)\n"
     ]
    }
   ],
   "source": [
    "dataReader = UTDReader(root_path='../data/UTD-MHAD-Inertial/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt \n",
    "\n",
    "# lens = [dataReader.data[i].shape[0] for i in range(dataReader.data.shape[0])]\n",
    "# plt.hist(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape : (861,), seen_data shape : (765,)\n",
      "{'swipe left': 32, 'swipe right': 32, 'wave': 32, 'clap': 32, 'throw': 32, 'arm cross': 32, 'basketball shoot': 32, 'draw x': 31, 'draw circle(clockwise)': 32, 'draw circle(counter clockwise)': 32, 'draw triangle': 32, 'bowling': 32, 'boxing': 32, 'baseball swing': 32, 'tennis swing': 32, 'arm curl': 32, 'tennis serve': 32, 'push': 32, 'knock': 32, 'catch': 32, 'pickup & throw': 32, 'jog': 32, 'walk': 31, 'sit to stand': 32, 'stand to sit': 32, 'lunge': 32, 'squat': 31}\n",
      "(2126, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "data_dict = dataReader.generate(unseen_classes=[2, 3, 4],  window_size=2, window_overlap=1.5, resample_freq=50, smoothing=False, normalize=False, seen_ratio=0.2, unseen_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swipe left',\n",
       " 'swipe right',\n",
       " 'wave',\n",
       " 'clap',\n",
       " 'throw',\n",
       " 'arm cross',\n",
       " 'basketball shoot',\n",
       " 'draw x',\n",
       " 'draw circle(clockwise)',\n",
       " 'draw circle(counter clockwise)',\n",
       " 'draw triangle',\n",
       " 'bowling',\n",
       " 'boxing',\n",
       " 'baseball swing',\n",
       " 'tennis swing',\n",
       " 'arm curl',\n",
       " 'tennis serve',\n",
       " 'push',\n",
       " 'knock',\n",
       " 'catch',\n",
       " 'pickup & throw',\n",
       " 'jog',\n",
       " 'walk',\n",
       " 'sit to stand',\n",
       " 'stand to sit',\n",
       " 'lunge',\n",
       " 'squat']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataReader.idToLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training samples :  1700\n",
      "per class count :  {0: 50, 1: 46, 5: 60, 6: 45, 7: 66, 8: 82, 9: 78, 10: 85, 11: 104, 12: 69, 13: 95, 14: 69, 15: 51, 16: 71, 17: 48, 18: 69, 19: 39, 20: 131, 21: 58, 22: 87, 23: 38, 24: 48, 25: 103, 26: 108}\n"
     ]
    }
   ],
   "source": [
    "# training dataset\n",
    "train_X, train_y = data_dict['train']['X'], data_dict['train']['y']\n",
    "print(\"number of training samples : \", len(train_y))\n",
    "s = np.unique(train_y, return_counts=True)\n",
    "print(\"per class count : \", dict(zip(s[0], s[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training samples :  426\n",
      "per class count :  {0: 10, 1: 8, 5: 15, 6: 17, 7: 13, 8: 27, 9: 23, 10: 28, 11: 25, 12: 12, 13: 18, 14: 14, 15: 7, 16: 18, 17: 16, 18: 16, 19: 13, 20: 21, 21: 20, 22: 22, 23: 9, 24: 8, 25: 44, 26: 22}\n"
     ]
    }
   ],
   "source": [
    "# Seen Evaluation dataset\n",
    "Seval_X, Seval_y = data_dict['eval-seen']['X'], data_dict['eval-seen']['y']\n",
    "print(\"number of training samples : \", len(Seval_y))\n",
    "s = np.unique(Seval_y, return_counts=True)\n",
    "print(\"per class count : \", dict(zip(s[0], s[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training samples :  199\n",
      "per class count :  {2: 81, 3: 63, 4: 55}\n"
     ]
    }
   ],
   "source": [
    "# Unseen Eval dataset\n",
    "test_X, test_y = data_dict['test']['X'], data_dict['test']['y']\n",
    "print(\"number of training samples : \", len(test_y))\n",
    "s = np.unique(test_y, return_counts=True)\n",
    "print(\"per class count : \", dict(zip(s[0], s[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict['test']['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points :  2325\n",
      "Total number of unseen data :  199\n",
      "Total number of seen data :  2126\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of data points : \", len(test_y)+len(Seval_y)+len(train_y))\n",
    "print(\"Total number of unseen data : \", len(test_y))\n",
    "print(\"Total number of seen data : \", len(Seval_y)+len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UTDDataset(Dataset):\n",
    "    def __init__(self, data, actions, attributes, action_feats, action_classes, seq_len=120):\n",
    "        super(UTDDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.actions = actions\n",
    "        self.attributes = torch.from_numpy(attributes)\n",
    "        self.action_feats = torch.from_numpy(action_feats)\n",
    "        self.target_feat = torch.from_numpy(action_feats[action_classes, :])\n",
    "        self.seq_len = seq_len\n",
    "        # build action to id mapping dict\n",
    "        self.n_action = len(self.actions)\n",
    "        self.action2Id = dict(zip(action_classes, range(self.n_action)))\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        x = self.data[ind]\n",
    "        x_len = x.shape[0]\n",
    "        if x_len > self.seq_len:\n",
    "            randIndex = random.sample(range(x_len), self.seq_len)\n",
    "            randIndex.sort()\n",
    "            x = x[randIndex, :]\n",
    "        else:\n",
    "            print(x_len)\n",
    "        x_mask = np.array([0]) #self.padding_mask[ind, ...]\n",
    "        target = self.actions[ind]\n",
    "        y = torch.from_numpy(np.array([self.action2Id[target]]))\n",
    "        y_feat = self.action_feats[target, ...]\n",
    "        attr = self.attributes[target, ...]\n",
    "        return torch.from_numpy(x), y, y_feat, attr, x_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = dataReader.idToLabel\n",
    "seen_classes = data_dict['seen_classes']\n",
    "unseen_classes = data_dict['unseen_classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_mat = np.zeros((27, 32))\n",
    "feat_mat = np.zeros((27, 42))\n",
    "train_dt = UTDDataset(data=data_dict['train']['X'], actions=data_dict['train']['y'], attributes=attr_mat, action_feats=feat_mat, action_classes=seen_classes, seq_len=100)\n",
    "train_dl = DataLoader(train_dt, batch_size=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100, 6])\n"
     ]
    }
   ],
   "source": [
    "for b in train_dl:\n",
    "    x, y, yf, attr, xm = b\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mvts_trans')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccc35149ad8fa032444ebff1245e6ef176e6c1ce3af8dec48e3374f21a6b0f27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
