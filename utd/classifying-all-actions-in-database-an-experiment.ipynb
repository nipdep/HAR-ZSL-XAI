{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "   \"\"\"  for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\"\"\"\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have 27 different human pose actions.The actions are (1) right arm swipe to the left, (2) right arm swipe to the right, (3) right hand wave, (4) two hand front clap, (5) right arm throw, (6) cross arms in the chest, (7) basketball shoot, (8) right hand draw x, (9) right hand draw circle (clockwise), (10) right hand draw circle (counter clockwise), (11) draw triangle, (12) bowling (right hand), (13) front boxing, (14) baseball swing from right, (15) tennis right hand forehand swing, (16) arm curl (two arms), (17) tennis serve, (18) two hand push, (19) right hand knock on door, (20) right hand catch an object, (21) right hand pick up and throw, (22) jogging in place, (23) walking in place, (24) sit to stand, (25) stand to sit, (26) forward lunge (left foot forward), (27) squat (two arms stretch out).**\n",
    "\n",
    "\n",
    "**We will classify all actions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to combine multiple dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineMultipleDatas(data_names):\n",
    "   datas = data_names[0]\n",
    "   x = 0\n",
    "   for data in data_names:\n",
    "       if x == 0:\n",
    "           result = datas.append(data,ignore_index=True)\n",
    "       else:\n",
    "           result = result.append(data,ignore_index=True)\n",
    "       x = x+ 1\n",
    "   return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A function to make flatten data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataTableOptimizerUpdated(mat_file):\n",
    "    our_data = mat_file['d_skel']\n",
    "    datas = []\n",
    "    frame_size = len(our_data[0][0])-1\n",
    "    for each in range(0,frame_size):\n",
    "        data_flatten = our_data[:,:,each].flatten()\n",
    "        data_flatten = data_flatten[np.newaxis]\n",
    "        datas.append(data_flatten)\n",
    "    return datas,frame_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main function to Load correct .mat files and convert it to dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loader(path,chosen_class_number):\n",
    "    full_list = []\n",
    "    for entry in sorted(os.listdir(path)):\n",
    "        if os.path.isfile(os.path.join(path, entry)):\n",
    "            mat = scipy.io.loadmat(path+entry)\n",
    "            all_data, frame = dataTableOptimizerUpdated(mat_file=mat)\n",
    "            full_list.extend(all_data)\n",
    "    #data_ready = dataTableForCluster2(data=full_list,joint_names=joint_names,column_names=col_names,frame=len(full_list))\n",
    "    full_list = np.concatenate(full_list)\n",
    "    data_re = pd.DataFrame(full_list)\n",
    "    data_re['classs'] = np.full((1,len(data_re)),chosen_class_number).T\n",
    "    return data_re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First we define root path.The root path is dataset path and it contains 27 folders include 27 action.Then, we add path to corresponding action folder and we Load dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"//kaggle//input//human-action-recognition-dataset//\"\n",
    "path= root_path + \"a1//\"\n",
    "a_1_files = Loader(path=path,chosen_class_number=1)\n",
    "path = root_path + \"a2//\"\n",
    "a_2_files = Loader(path,chosen_class_number=2)\n",
    "path = root_path + \"a3//\"\n",
    "a_3_files = Loader(path,chosen_class_number=3)\n",
    "path = root_path + \"a4//\"\n",
    "a_4_files = Loader(path,chosen_class_number=4)\n",
    "path = root_path + \"a5//\"\n",
    "a_5_files = Loader(path,chosen_class_number=5)\n",
    "path = root_path + \"a6//\"\n",
    "a_6_files = Loader(path,chosen_class_number=6)\n",
    "path = root_path + \"a7//\"\n",
    "a_7_files = Loader(path,chosen_class_number=7)\n",
    "path = root_path + \"a8//\"\n",
    "a_8_files = Loader(path,chosen_class_number=8)\n",
    "path = root_path + \"a9//\"\n",
    "a_9_files = Loader(path,chosen_class_number=9)\n",
    "path = root_path + \"a10//\"\n",
    "a_10_files = Loader(path,chosen_class_number=10)\n",
    "path = root_path + \"a11//\"\n",
    "a_11_files = Loader(path,chosen_class_number=11)\n",
    "path = root_path + \"a12//\"\n",
    "a_12_files = Loader(path,chosen_class_number=12)\n",
    "path = root_path + \"a13//\"\n",
    "a_13_files = Loader(path,chosen_class_number=13)\n",
    "path = root_path + \"a14//\"\n",
    "a_14_files = Loader(path,chosen_class_number=14)\n",
    "path = root_path + \"a15//\"\n",
    "a_15_files = Loader(path,chosen_class_number=15)\n",
    "path = root_path + \"a16//\"\n",
    "a_16_files = Loader(path,chosen_class_number=16)\n",
    "path = root_path + \"a17//\"\n",
    "a_17_files = Loader(path,chosen_class_number=17)\n",
    "path = root_path + \"a18//\"\n",
    "a_18_files = Loader(path,chosen_class_number=18)\n",
    "path = root_path + \"a19//\"\n",
    "a_19_files = Loader(path,chosen_class_number=19)\n",
    "path = root_path + \"a20//\"\n",
    "a_20_files = Loader(path,chosen_class_number=20)\n",
    "path = root_path + \"a21//\"\n",
    "a_21_files = Loader(path,chosen_class_number=21)\n",
    "path = root_path + \"a22//\"\n",
    "a_22_files = Loader(path,chosen_class_number=22)\n",
    "path = root_path + \"a23//\"\n",
    "a_23_files = Loader(path,chosen_class_number=23)\n",
    "path = root_path + \"a24//\"\n",
    "a_24_files = Loader(path,chosen_class_number=24)\n",
    "path = root_path + \"a25//\"\n",
    "a_25_files = Loader(path,chosen_class_number=25)\n",
    "path = root_path + \"a26//\"\n",
    "a_26_files = Loader(path,chosen_class_number=26)\n",
    "path = root_path + \"a27//\"\n",
    "a_27_files = Loader(path,chosen_class_number=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We define a list about data with dataframe included, then we combine all datas in one dataframe with classes included which we define 'out'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names = [a_1_files,a_2_files,a_3_files,a_4_files,a_5_files,a_6_files,a_7_files,a_8_files,a_9_files,a_10_files,a_11_files,a_12_files,a_13_files,a_14_files,a_15_files,a_16_files,a_17_files,a_18_files,a_19_files,a_20_files,a_21_files,a_22_files,a_23_files,a_24_files,a_25_files,a_26_files,a_27_files]\n",
    "out = combineMultipleDatas(data_names=data_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We split data as 'class' columns and the other columns as data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = out.drop([\"classs\"],axis=1)\n",
    "y = out.classs.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We split the datas as train test with ratio 75%/25%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We call multiple classifiers and fit all of them then measure the score with test data to see Accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc of svm is : 0.32452830188679244\n",
      "Random Forest accuracy on test data is :  0.9986522911051213\n",
      "k=3 nn score:0.946900269541779\n",
      "accuracy of bayes in test data is : 0.3267520215633423\n",
      "acc_of_sgd is:  0.35444743935309975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 4) #n_neighbors = k\n",
    "knn.fit(x_train,y_train)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100,random_state=1)\n",
    "rf.fit(x_train,y_train)\n",
    "\n",
    "svm = SVC(random_state = 1)\n",
    "svm.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "print(\"acc of svm is :\",svm.score(x_test,y_test))\n",
    "print('Random Forest accuracy on test data is : ',rf.score(x_test,y_test))\n",
    "print(\"k={} nn score:{}\".format(3,knn.score(x_test,y_test)))\n",
    "print('accuracy of bayes in test data is :', nb.score(x_test,y_test))\n",
    "print('acc_of_sgd is: ', sgd.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results show that Random Forest has best accuracy.So I choose random forest to make cross validation and see confusion matrix, but in kaggle sklearn version is not updated, so we can't use confusion matrix func**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_confusion_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cfc25b46bd92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'swipe left'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'swipe right'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wave'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'clap'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'throw'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'arm cross'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'basketball shot'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'draw x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'draw circle(clockwise)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'draw circle(counter_cloclwise)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'draw triangle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bowling'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'boxing'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'baseball swing'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tennis swing'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'arm curl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tennis serve'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'push'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'knock'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'catch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pickup-throw'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'jog'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'walk'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sit_to_stand'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'stand_to_sit'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lunge'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'squat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m titles_options = [(\"Confusion matrix, without normalization\", None),\n\u001b[1;32m      5\u001b[0m                   (\"Normalized confusion matrix\", 'true')]\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_confusion_matrix'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "class_names=['swipe left','swipe right','wave','clap','throw','arm cross','basketball shot','draw x','draw circle(clockwise)','draw circle(counter_cloclwise)','draw triangle','bowling','boxing','baseball swing','tennis swing','arm curl','tennis serve','push','knock','catch','pickup-throw','jog','walk','sit_to_stand','stand_to_sit','lunge','squat']\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(rf, x_test, y_test,\n",
    "                                 display_labels=class_names,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try 10 fold cross validation to see is the algorithm really good?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg acc:  0.9976181176998413\n",
      "acg std:  0.000692434404242862\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "accuracy = cross_val_score(estimator = rf, X = x_train, y =y_train, cv = 10)\n",
    "print(\"avg acc: \",np.mean(accuracy))\n",
    "print(\"acg std: \",np.std(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results show that mean accuracy is really high and standart deviation is very low which says the accuracy scores are really close to each other.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ixd_base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "89d19bda3374b9e03b00ba690f1474ee82759215833505b4f4042b807e24ac85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
