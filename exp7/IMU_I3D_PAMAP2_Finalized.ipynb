{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJhThY8PC2si",
        "outputId": "d255d73f-8014-49c8-872d-5dcd96073c21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khVPupusDG8T",
        "outputId": "f9a41210-adce-43f2-bad5-83d6ca915c17"
      },
      "outputs": [],
      "source": [
        "! pip install neptune\n",
        "! git clone https://github.com/nipdep/HAR-ZSL-XAI.git --branch pd/PoseAE --single-branch\n",
        "! mv /content/HAR-ZSL-XAI/src /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G3REk2jDHN1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjkkcslBunGA"
      },
      "outputs": [],
      "source": [
        "data_root = '/content/drive/MyDrive/22_FYP42 - Zero-shot Explainable HAR/Datasets/Consolidated/PAMPA2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys \n",
        "sys.path.append('../')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWgMHHXXDG5n",
        "outputId": "b5be9350-b405-4793-ec2b-d910ac4793d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\deela\\AppData\\Local\\Temp\\ipykernel_13792\\1410821997.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "from datetime import date, datetime\n",
        "from tqdm.autonotebook import tqdm\n",
        "from copy import deepcopy\n",
        "from collections import defaultdict\n",
        "import numpy as np \n",
        "import numpy.random as random\n",
        "import pandas as pd\n",
        "import json\n",
        "import pickle\n",
        "from collections import defaultdict, OrderedDict\n",
        "import neptune\n",
        "\n",
        "import torch \n",
        "from torch import nn, Tensor\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.modules import MultiheadAttention, Linear, Dropout, BatchNorm1d, TransformerEncoderLayer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.nn import MSELoss\n",
        "\n",
        "\n",
        "from src.datasets.data import PAMAP2Reader, PAMAP2ReaderV2\n",
        "# from src.datasets.dataset import PAMAP2Dataset\n",
        "from src.utils.analysis import action_evaluator\n",
        "from src.datasets.utils import load_attribute\n",
        "\n",
        "from src.models.loss import FeatureLoss, AttributeLoss\n",
        "from src.utils.losses import *\n",
        "from src.utils.analysis import action_evaluator\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# from src.running import train_step1, eval_step1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "enxG_kfLUdK9"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "# from umap import UMAP\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "umHwAr5pDG2N"
      },
      "outputs": [],
      "source": [
        "# setup model configurations\n",
        "config = {\n",
        "    # general information\n",
        "    \"datetime\": date.today(),\n",
        "    \"device\": \"gpu\",\n",
        "    \"dataset\": \"PAMAP2\", # \"PAMAP2\", \"DaLiAc\", \"UTD\"\n",
        "    \"Model\": \"BiLSTM\",\n",
        "    \"sem-space\": 'I3D',\n",
        "    # model training configs\n",
        "    \"lr\": 0.001,\n",
        "    \"imu_alpha\": 0.0001,\n",
        "    \"n_epochs\": 15,\n",
        "    \"batch_size\": 32,\n",
        "    # model configs\n",
        "    \"d_model\": 128, \n",
        "    \"num_heads\": 2,\n",
        "    \"feat_size\": 400, # skel-AE hidden size and IMU-Anc output size\n",
        "    \"semantic_size\": 400,\n",
        "    # dataset configs\n",
        "    \"window_size\": 5.21, \n",
        "    \"overlap\": 4.21,\n",
        "    \"freq\": 20,\n",
        "    \"seq_len\": 50,  # skeleton seq. length\n",
        "    \"seen_split\": 0.1,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HpuaMQupDNPI"
      },
      "outputs": [],
      "source": [
        "def save_model(model,model_name,unique_name,fold_id):\n",
        "    PATH = f\"{models_saves}/{model_name}\"\n",
        "    os.makedirs(PATH,exist_ok=True)\n",
        "    torch.save({\n",
        "        \"n_epochs\" : config[\"n_epochs\"],\n",
        "        \"model_state_dict\":model.state_dict(),\n",
        "        \"config\": config\n",
        "    }, f\"{PATH}/{unique_name}_{fold_id}.pt\")\n",
        "\n",
        "model_iden = \"fold\"\n",
        "notebook_iden = \"SORTModel_feature\"\n",
        "models_saves = \"model_saves\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQcUv5ikFZyN",
        "outputId": "be8d5ad9-8b6c-4d59-efcc-dfa53c107aeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading file 1 of 14\n",
            "Reading file 2 of 14\n",
            "Reading file 3 of 14\n",
            "Reading file 4 of 14\n",
            "Reading file 5 of 14\n",
            "Reading file 6 of 14\n",
            "Reading file 7 of 14\n",
            "Reading file 8 of 14\n",
            "Reading file 9 of 14\n",
            "Reading file 10 of 14\n",
            "Reading file 11 of 14\n",
            "Reading file 12 of 14\n",
            "Reading file 13 of 14\n",
            "Reading file 14 of 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "g:\\FYP\\Codebases\\Pose-AE\\exp7\\..\\src\\datasets\\data.py:1275: VisibleDeprecationWarning:\n",
            "\n",
            "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# IMU_data_path = data_root+'/IMU/Protocol/'\n",
        "IMU_data_path = '../data/PAMAP2_Dataset/Protocol/'\n",
        "dataReader = PAMAP2ReaderV2(IMU_data_path)\n",
        "actionList = dataReader.idToLabel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZxOPxsMhyEF"
      },
      "outputs": [],
      "source": [
        "def read_I3D_pkl(loc,feat_size=\"400\"):\n",
        "  if feat_size == \"400\":\n",
        "    feat_index = 1\n",
        "  elif feat_size == \"2048\":\n",
        "    feat_index = 0\n",
        "  else:\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  with open(loc,\"rb\") as f0:\n",
        "    __data = pickle.load(f0)\n",
        "\n",
        "  label = []\n",
        "  prototype = []\n",
        "  for k,v in __data.items():\n",
        "    label.append(k)\n",
        "    all_arr = [x[feat_index] for x in v]\n",
        "    all_arr = np.asarray(all_arr).mean(axis=0)\n",
        "    prototype.append(all_arr)\n",
        "\n",
        "  label = np.asarray(label)\n",
        "  prototype = np.array(prototype)\n",
        "  return {\"activity\":label, \"features\":prototype}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAO5neZHGJKL"
      },
      "outputs": [],
      "source": [
        "# load video dataset\n",
        "# I3D_data_path  = data_root + '/I3D/video_feat.pkl'\n",
        "I3D_data_path  = './PAMAP2_Dataset/I3D/video_feat.pkl'\n",
        "video_data = read_I3D_pkl(I3D_data_path, feat_size=\"400\")\n",
        "video_classes, attr_mat = video_data['activity'], video_data['features']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqZLOjZrQLOf"
      },
      "outputs": [],
      "source": [
        "# re-arrange semantic space\n",
        "activity_dict = dict(zip(video_classes, attr_mat))\n",
        "semantic_space = np.array([activity_dict[c] for c in actionList])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMgevInhKbjy"
      },
      "outputs": [],
      "source": [
        "class PAMAP2Dataset(Dataset):\n",
        "    def __init__(self, data, actions, attributes, action_classes, seq_len=120):\n",
        "        super(PAMAP2Dataset, self).__init__()\n",
        "        self.data = torch.from_numpy(data)\n",
        "        self.actions = actions\n",
        "        self.seq_len = seq_len\n",
        "        self.attributes = torch.from_numpy(attributes)\n",
        "        self.action_classes = action_classes\n",
        "        # build action to id mapping dict\n",
        "        self.n_action = len(self.actions)\n",
        "        self.action2Id = dict(zip(action_classes, range(self.n_action)))\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        x = self.data[ind, ...]\n",
        "        target = self.actions[ind]\n",
        "        y = torch.from_numpy(np.array([self.action2Id[target]]))\n",
        "        # extraction semantic space generation skeleton sequences\n",
        "        y_feat = self.attributes[target, ...]\n",
        "        return x, y, y_feat\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def getClassAttrs(self):\n",
        "        sampling_idx = [random.choice(self.attribute_dict[i]) for i in self.action_classes]\n",
        "        ft_mat = self.attributes[sampling_idx, ...]\n",
        "        return ft_mat\n",
        "\n",
        "    def getClassFeatures(self):\n",
        "        cls_feat = self.attributes[self.action_classes, ...]\n",
        "        return cls_feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIWrGZwzUnbQ"
      },
      "outputs": [],
      "source": [
        "class IMUEncoder(nn.Module):\n",
        "    def __init__(self, in_ft, d_model, ft_size, n_classes, num_heads=1, max_len=1024, dropout=0.1):\n",
        "        super(IMUEncoder, self).__init__()\n",
        "        self.in_ft = in_ft\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.ft_size = ft_size \n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.in_ft,\n",
        "                            hidden_size=self.d_model,\n",
        "                            num_layers=self.num_heads,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=True)\n",
        "        self.drop = nn.Dropout(p=0.1)\n",
        "        self.act = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.fcLayer1 = nn.Linear(2*self.d_model, self.ft_size)\n",
        "        # self.fcLayer2 = nn.Linear(self.ft_size, self.ft_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out_forward = out[:, self.max_len - 1, :self.d_model]\n",
        "        out_reverse = out[:, 0, self.d_model:]\n",
        "        out_reduced = torch.cat((out_forward, out_reverse), 1)\n",
        "        out = self.drop(out_reduced)\n",
        "        out = self.act(out)\n",
        "        out = self.fcLayer1(out)\n",
        "        out = self.sigmoid(out)\n",
        "        # out = self.fcLayer2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKpMzwHKGAQ2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsH-K0HpF7tu"
      },
      "outputs": [],
      "source": [
        "if config['device'] == 'cpu':\n",
        "    device = \"cpu\"\n",
        "else:\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9Lp6g_IGCJs"
      },
      "outputs": [],
      "source": [
        "# run 5-fold running\n",
        "fold_classes = [['watching TV', 'house cleaning', 'standing', 'ascending stairs'], ['walking', 'rope jumping', 'sitting', 'descending stairs'], ['playing soccer', 'lying', 'vacuum cleaning', 'computer work'], ['cycling', 'running', 'Nordic walking'], ['ironing', 'car driving', 'folding laundry']]\n",
        "\n",
        "fold_cls_ids = [[actionList.index(i) for i in j] for j in fold_classes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBzAK08GHu6z"
      },
      "outputs": [],
      "source": [
        "def loss_cross_entropy(y_pred, y, feat, loss_fn=nn.CrossEntropyLoss(reduction=\"mean\")):\n",
        "    mm_vec = torch.mm(y_pred, torch.transpose(feat, 0, 1))\n",
        "    feat_norm = torch.norm(feat, p=2, dim=1)\n",
        "    norm_vec = mm_vec/torch.unsqueeze(feat_norm, 0)\n",
        "    softmax_vec = torch.softmax(norm_vec, dim=1)\n",
        "    output = loss_fn(softmax_vec, y)\n",
        "    return output\n",
        "\n",
        "def tripletLoss(pred_feat, y, feats, loss_fn=nn.TripletMarginLoss(margin=0.1, p=2)):\n",
        "    pos_feats = feats[y].unsqueeze(1)\n",
        "    anchor_feat = pred_feat.unsqueeze(1)\n",
        "    index_2d = [torch.arange(32), y]\n",
        "    batch_feats = feats.unsqueeze(0).repeat(32, 1, 1)\n",
        "    neg_feats = batch_feats.index_put(indices=index_2d, values=torch.tensor(0.))\n",
        "    # print(pos_feats.shape, anchor_feat.shape, neg_feats.shape)\n",
        "    output = loss_fn(anchor_feat, pos_feats, neg_feats)\n",
        "    return output\n",
        "\n",
        "\n",
        "def predict_class(y_pred, selected_features):\n",
        "\n",
        "    num_classes = selected_features.size()[0]\n",
        "\n",
        "    cosine_sim_comb = []\n",
        "    for entry in y_pred.unbind():\n",
        "        cosine_sim = torch.argmax(F.softmax(torch.abs(F.cosine_similarity(entry.repeat(num_classes,1),selected_features)),dim=-1))\n",
        "        cosine_sim_comb.append(cosine_sim)\n",
        "\n",
        "    pred = torch.stack(cosine_sim_comb)\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOS3PISDH6ir"
      },
      "outputs": [],
      "source": [
        "def train_step(model, dataloader, dataset:PAMAP2Dataset, optimizer, loss_module, device, class_names, phase='train', l2_reg=False, loss_alpha=0.7):\n",
        "    model = model.train()\n",
        "    epoch_loss = 0  # total loss of epoch\n",
        "    total_samples = 0  # total samples in epoch\n",
        "    random_selected_feat = dataset.getClassFeatures().to(device)\n",
        "\n",
        "    with tqdm(dataloader, unit=\"batch\", desc=phase) as tepoch:\n",
        "        for batch in tepoch:\n",
        "            X, targets, target_feat = batch\n",
        "            X = X.float().to(device)\n",
        "            target_feat = target_feat.float().to(device)\n",
        "            targets = targets.long().to(device)\n",
        "\n",
        "            # Zero gradients, perform a backward pass, and update the weights.\n",
        "            optimizer.zero_grad()\n",
        "            # forward track history if only in train\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "            # with autocast():\n",
        "                feat_output = model(X)\n",
        "                class_loss = loss_cross_entropy(feat_output, targets.squeeze(), random_selected_feat, loss_fn =loss_module['class'] )\n",
        "                feat_loss = tripletLoss(feat_output, targets.squeeze(), random_selected_feat, loss_fn=loss_module[\"feature\"])\n",
        "\n",
        "            #loss = cross_entropy_loss\n",
        "            loss = feat_loss + loss_alpha*class_loss\n",
        "            class_output = predict_class(feat_output, random_selected_feat)\n",
        "\n",
        "            if phase == 'train':\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            metrics = {\"loss\": loss.item()}\n",
        "            with torch.no_grad():\n",
        "                total_samples += len(targets)\n",
        "                epoch_loss += loss.item()  # add total loss of batch\n",
        "\n",
        "            # convert feature vector into action class using cosine\n",
        "            pred_class = class_output.cpu().detach().numpy()\n",
        "            metrics[\"accuracy\"] = accuracy_score(y_true=targets.cpu().detach().numpy(), y_pred=pred_class)\n",
        "            tepoch.set_postfix(metrics)\n",
        "\n",
        "    epoch_loss = epoch_loss / total_samples  # average loss per sample for whole epoch\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYNZfoaMH_Xr"
      },
      "outputs": [],
      "source": [
        "def eval_step(model, dataloader,dataset, loss_module, device, class_names,  phase='seen', l2_reg=False, print_report=True, loss_alpha=0.7):\n",
        "    model = model.eval()\n",
        "    epoch_loss = 0  # total loss of epoch\n",
        "    total_samples = 0  # total samples in epoch\n",
        "    random_selected_feat = dataset.getClassFeatures().to(device)\n",
        "    per_batch = {'target_masks': [], 'targets': [], 'predictions': [], 'metrics': [], 'IDs': []}\n",
        "    metrics = {\"samples\": 0, \"loss\": 0, \"feat. loss\": 0, \"classi. loss\": 0}\n",
        "\n",
        "    with tqdm(dataloader, unit=\"batch\", desc=phase) as tepoch:\n",
        "        for batch in tepoch:\n",
        "            X, targets, target_feat = batch\n",
        "            X = X.float().to(device)\n",
        "            target_feat = target_feat.float().to(device)\n",
        "            targets = targets.long().to(device)\n",
        "\n",
        "            # forward track history if only in train\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "            # with autocast():\n",
        "                feat_output = model(X)\n",
        "                class_loss = loss_cross_entropy(feat_output, targets.squeeze(), random_selected_feat, loss_fn =loss_module['class'] )\n",
        "                feat_loss = tripletLoss(feat_output, targets.squeeze(), random_selected_feat, loss_fn=loss_module[\"feature\"])\n",
        "            \n",
        "            loss = feat_loss + loss_alpha*class_loss\n",
        "            class_output = predict_class(feat_output, random_selected_feat)\n",
        "\n",
        "            # convert feature vector into action class using cosine\n",
        "            if phase == 'seen':\n",
        "                pred_action = class_output\n",
        "            else:\n",
        "                #feat_numpy = torch.sigmoid(feat_output.cpu().detach())\n",
        "                #action_probs = cosine_similarity(feat_numpy, target_feat_met)\n",
        "                pred_action = class_output\n",
        "\n",
        "            with torch.no_grad():\n",
        "                metrics['samples'] += len(targets)\n",
        "                metrics['loss'] += loss.item()  # add total loss of batch\n",
        "                metrics['feat. loss'] += feat_loss.item()\n",
        "                metrics['classi. loss'] += class_loss.item()\n",
        "\n",
        "            per_batch['targets'].append(targets.cpu().numpy())\n",
        "            per_batch['predictions'].append(pred_action.cpu().numpy())\n",
        "            per_batch['metrics'].append([loss.cpu().numpy()])\n",
        "\n",
        "            tepoch.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "    all_preds = np.concatenate(per_batch[\"predictions\"])\n",
        "    all_targets = np.concatenate(per_batch[\"targets\"])\n",
        "    metrics_dict = action_evaluator(y_pred=all_preds, y_true=all_targets[:, 0], class_names=class_names, print_report=print_report)\n",
        "    metrics_dict.update(metrics)\n",
        "    return metrics_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf2ful7mTOix"
      },
      "outputs": [],
      "source": [
        "def plot_curves(df):\n",
        "    df['loss'] = df['loss']/df['samples']\n",
        "    df['feat. loss'] = df['feat. loss']/df['samples']\n",
        "    df['classi. loss'] = df['classi. loss']/df['samples']\n",
        "    \n",
        "    fig, axs = plt.subplots(nrows=4)\n",
        "    sns.lineplot(data=df, x='epoch', y='loss', hue='phase', marker='o', ax=axs[2]).set(title=\"Loss\")\n",
        "    sns.lineplot(data=df, x='epoch', y='feat. loss', hue='phase', marker='o', ax=axs[0]).set(title=\"Feature Loss\")\n",
        "    sns.lineplot(data=df, x='epoch', y='classi. loss', hue='phase', marker='o', ax=axs[1]).set(title=\"Classification Loss\")\n",
        "    sns.lineplot(data=df, x='epoch', y='accuracy', hue='phase', marker='o', ax=axs[3]).set(title=\"Accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IdfvX3s11U7"
      },
      "outputs": [],
      "source": [
        "def log(fold, phase, metrics):\n",
        "    for m, v in metrics.items():\n",
        "        if fold == 'global':\n",
        "            run[f'global/{m}'].log(v)\n",
        "        else:\n",
        "            run[f\"Fold-{fold}/{phase}/{m}\"].log(v) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOctuOEp1xlx",
        "outputId": "48f6af6d-e524-432e-a561-bf52563d2bbc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-0fd58e113600>:1: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
            "  run = neptune.init_run(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://app.neptune.ai/FYP-Group22/ICANN-Logs/e/IC-22\n"
          ]
        }
      ],
      "source": [
        "run = neptune.init_run(\n",
        "    project=\"FYP-Group22/ICANN-Logs\",\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJkNWJjMDdhNC05NWY5LTQwNWQtYTQyNi0zNjNmYmYwZDg3M2YifQ==\",\n",
        ")  # your credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8601a6a245fd4f7eadc97b48d10cd54b",
            "6511fb4c054f45a4b509a43339666c3f",
            "0e1b2786f0e44c2d9d4aab1f453230e1",
            "d6bbe1656fb74a0db1178dd05e4741fd",
            "2599a0dad80047da89ef69a86b031126",
            "dd09bb87351b46c382978a491f226e6d",
            "53e4e9b5912e4feb826f86eba5849cbd",
            "7df631a1c8364c51a93422a2c4116e0f",
            "36391b3d917149e1bb2357dd382cedbb",
            "09e5693563094338a1a06f22cea202a0",
            "9128a4798a0249f7b9acfb404b277190",
            "3414947a3a0e403092050bdfb7e4d7ca",
            "04bef2bd09cc436bb64d17c716b23a21",
            "095934a18a3a4dbe8595ccfa8f54fedb",
            "1a1dd862bfc146408557a065671af63b",
            "07e2e431cb6840f49812e20bf4832532",
            "acc858d7b15040ff925818726250ccd5",
            "827714c3c4fb4eafac1377ac4adc975b",
            "885e8b0d99174ef3bcff55b46b7d24a6",
            "402043caafa343e389a127a748024a5a",
            "486d50d223794b0a93f942fe668d0a3d",
            "5e4564f92bb54cb397891e7d71d2b6d3"
          ]
        },
        "id": "ezbEvFA9IA_K",
        "outputId": "9bd72ed0-8eee-41a5-af32-49e838f95219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================ Fold-0 ================\n",
            "Unseen Classes : ['watching TV', 'house cleaning', 'standing', 'ascending stairs']\n",
            "seen classes >  [0, 1, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 16, 17]\n",
            "unseen classes >  [7, 15, 2, 10]\n",
            "Initiate IMU datasets ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8601a6a245fd4f7eadc97b48d10cd54b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch:   0%|          | 0/15 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3414947a3a0e403092050bdfb7e4d7ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train:   0%|          | 0/588 [00:00<?, ?batch/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n",
            "y_pred >  torch.Size([32, 400]) cls >  torch.Size([32]) selected_features >  torch.Size([14, 400])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-29e7d526651c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'phase'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-d7e9a7efd900>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, dataloader, dataset, optimizer, loss_module, device, class_names, phase, l2_reg, loss_alpha)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#loss = cross_entropy_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_alpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mclass_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mclass_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_selected_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-83a54da8cdf7>\u001b[0m in \u001b[0;36mpredict_class\u001b[0;34m(y_pred, selected_features)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcosine_sim_comb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mcosine_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mcosine_sim_comb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# run['parameters'] = config\n",
        "fold_metric_scores = []\n",
        "\n",
        "for i, cs in enumerate(fold_cls_ids):\n",
        "    print(\"=\"*16, f'Fold-{i}', \"=\"*16)\n",
        "    print(f'Unseen Classes : {fold_classes[i]}')\n",
        "\n",
        "    data_dict = dataReader.generate(unseen_classes=cs, seen_ratio=config['seen_split'], unseen_ratio=0.8, window_size=config['window_size'], window_overlap=config['overlap'], resample_freq=config['freq'])\n",
        "    all_classes = dataReader.idToLabel\n",
        "    seen_classes = data_dict['seen_classes']\n",
        "    unseen_classes = data_dict['unseen_classes']\n",
        "    print(\"seen classes > \", seen_classes)\n",
        "    print(\"unseen classes > \", unseen_classes)\n",
        "    train_n, seq_len, in_ft = data_dict['train']['X'].shape\n",
        "\n",
        "    print(\"Initiate IMU datasets ...\")\n",
        "    # build IMU datasets\n",
        "    train_dt = PAMAP2Dataset(data=data_dict['train']['X'], actions=data_dict['train']['y'], attributes=semantic_space, action_classes=seen_classes, seq_len=100)\n",
        "    train_dl = DataLoader(train_dt, batch_size=config['batch_size'], shuffle=True, pin_memory=True, drop_last=True)\n",
        "    # build seen eval_dt\n",
        "    eval_dt = PAMAP2Dataset(data=data_dict['eval-seen']['X'], actions=data_dict['eval-seen']['y'], attributes=semantic_space, action_classes=seen_classes, seq_len=100)\n",
        "    eval_dl = DataLoader(eval_dt, batch_size=config['batch_size'], shuffle=True, pin_memory=True, drop_last=True)\n",
        "    # build unseen test_dt\n",
        "    test_dt = PAMAP2Dataset(data=data_dict['test']['X'], actions=data_dict['test']['y'], attributes=semantic_space, action_classes=unseen_classes, seq_len=100)\n",
        "    test_dl = DataLoader(test_dt, batch_size=config['batch_size'], shuffle=True, pin_memory=True, drop_last=True)\n",
        "    \n",
        "    # build model\n",
        "    imu_config = {\n",
        "        'in_ft':in_ft, \n",
        "        'd_model':config['d_model'], \n",
        "        'num_heads':config['num_heads'], \n",
        "        'ft_size':config['feat_size'], \n",
        "        'max_len':seq_len, \n",
        "        'n_classes':len(seen_classes)\n",
        "    }\n",
        "    model = IMUEncoder(**imu_config)\n",
        "    model.to(device)\n",
        "\n",
        "    # define run parameters \n",
        "    optimizer = Adam(model.parameters(), lr=config['lr'], weight_decay=1e-5)\n",
        "    loss_module = {'class': nn.CrossEntropyLoss(reduction=\"sum\"), 'feature': nn.L1Loss(reduction=\"sum\")}\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # train the model \n",
        "    train_data = []\n",
        "    for epoch in tqdm(range(config['n_epochs']), desc='Training Epoch', leave=False):\n",
        "    \n",
        "        train_metrics = train_step(model, train_dl, train_dt,optimizer, loss_module, device, class_names=[all_classes[i] for i in seen_classes], phase='train', loss_alpha=0.0001)\n",
        "        train_metrics['epoch'] = epoch\n",
        "        train_metrics['phase'] = 'train'\n",
        "        train_data.append(train_metrics)\n",
        "        log(i, 'train', train_metrics)\n",
        "\n",
        "        eval_metrics = eval_step(model, eval_dl, eval_dt,loss_module, device, class_names=[all_classes[i] for i in seen_classes], phase='seen', loss_alpha=0.0001, print_report=False)\n",
        "        eval_metrics['epoch'] = epoch \n",
        "        eval_metrics['phase'] = 'valid'\n",
        "        train_data.append(eval_metrics)\n",
        "        log(i, 'valid', train_metrics)\n",
        "        # print(f\"EPOCH [{epoch}] TRAINING : {train_metrics}\")\n",
        "        # print(f\"EPOCH [{epoch}] EVAL : {eval_metrics}\")\n",
        "        if eval_metrics['accuracy'] > best_acc:\n",
        "            best_model = deepcopy(model.state_dict())\n",
        "    \n",
        "    train_df = pd.DataFrame().from_records(train_data)\n",
        "    plot_curves(train_df)\n",
        "\n",
        "    # replace by best model \n",
        "    model.load_state_dict(best_model)\n",
        "    # save_model(model,notebook_iden,model_iden,i)\n",
        "\n",
        "    # run evaluation on unseen classes\n",
        "    test_metrics = eval_step(model, test_dl,test_dt, loss_module, device, class_names=[all_classes[i] for i in unseen_classes], phase='unseen', loss_alpha=0.0001, print_report=False)\n",
        "    fold_metric_scores.append(test_metrics)\n",
        "    log('test', i, test_metrics)\n",
        "    print(test_metrics)\n",
        "    print(\"=\"*40)\n",
        "\n",
        "print(\"=\"*14, \"Overall Unseen Classes Performance\", \"=\"*14)\n",
        "seen_score_df = pd.DataFrame.from_records(fold_metric_scores)\n",
        "print(seen_score_df.mean())\n",
        "log('global', '',seen_score_df.mean().to_dict())\n",
        "run.stop()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpSPnALYIC-N"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04bef2bd09cc436bb64d17c716b23a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acc858d7b15040ff925818726250ccd5",
            "placeholder": "​",
            "style": "IPY_MODEL_827714c3c4fb4eafac1377ac4adc975b",
            "value": "train:  17%"
          }
        },
        "07e2e431cb6840f49812e20bf4832532": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095934a18a3a4dbe8595ccfa8f54fedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_885e8b0d99174ef3bcff55b46b7d24a6",
            "max": 588,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_402043caafa343e389a127a748024a5a",
            "value": 102
          }
        },
        "09e5693563094338a1a06f22cea202a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e1b2786f0e44c2d9d4aab1f453230e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7df631a1c8364c51a93422a2c4116e0f",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36391b3d917149e1bb2357dd382cedbb",
            "value": 0
          }
        },
        "1a1dd862bfc146408557a065671af63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_486d50d223794b0a93f942fe668d0a3d",
            "placeholder": "​",
            "style": "IPY_MODEL_5e4564f92bb54cb397891e7d71d2b6d3",
            "value": " 102/588 [00:04&lt;00:14, 32.96batch/s, loss=46.1, accuracy=0.219]"
          }
        },
        "2599a0dad80047da89ef69a86b031126": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3414947a3a0e403092050bdfb7e4d7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04bef2bd09cc436bb64d17c716b23a21",
              "IPY_MODEL_095934a18a3a4dbe8595ccfa8f54fedb",
              "IPY_MODEL_1a1dd862bfc146408557a065671af63b"
            ],
            "layout": "IPY_MODEL_07e2e431cb6840f49812e20bf4832532"
          }
        },
        "36391b3d917149e1bb2357dd382cedbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "402043caafa343e389a127a748024a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "486d50d223794b0a93f942fe668d0a3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e4e9b5912e4feb826f86eba5849cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e4564f92bb54cb397891e7d71d2b6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6511fb4c054f45a4b509a43339666c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd09bb87351b46c382978a491f226e6d",
            "placeholder": "​",
            "style": "IPY_MODEL_53e4e9b5912e4feb826f86eba5849cbd",
            "value": "Training Epoch:   0%"
          }
        },
        "7df631a1c8364c51a93422a2c4116e0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "827714c3c4fb4eafac1377ac4adc975b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8601a6a245fd4f7eadc97b48d10cd54b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6511fb4c054f45a4b509a43339666c3f",
              "IPY_MODEL_0e1b2786f0e44c2d9d4aab1f453230e1",
              "IPY_MODEL_d6bbe1656fb74a0db1178dd05e4741fd"
            ],
            "layout": "IPY_MODEL_2599a0dad80047da89ef69a86b031126"
          }
        },
        "885e8b0d99174ef3bcff55b46b7d24a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9128a4798a0249f7b9acfb404b277190": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acc858d7b15040ff925818726250ccd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6bbe1656fb74a0db1178dd05e4741fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09e5693563094338a1a06f22cea202a0",
            "placeholder": "​",
            "style": "IPY_MODEL_9128a4798a0249f7b9acfb404b277190",
            "value": " 0/15 [00:04&lt;?, ?it/s]"
          }
        },
        "dd09bb87351b46c382978a491f226e6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
